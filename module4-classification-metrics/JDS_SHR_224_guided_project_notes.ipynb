{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "provenance": []
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZyiOteN16cD"
   },
   "source": [
    "## BloomTech Data Science\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KMI2k-oBsS08"
   },
   "source": [
    "# Classification Metrics\n",
    "\n",
    "- get and interpret the **confusion matrix** for classification models\n",
    "- use classification metrics: **precision, recall**\n",
    "- understand the relationships between precision, recall, **thresholds, and predicted probabilities**, to help **make decisions and allocate budgets**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wXNKAp0MFnXW"
   },
   "source": [
    "%%capture\n",
    "!pip install category_encoders==2.*"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z03W-t5_B8TY",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c9f58239-f263-416f-b8a0-6ed055784835",
    "ExecuteTime": {
     "end_time": "2023-07-06T14:52:38.838317Z",
     "start_time": "2023-07-06T14:52:38.103642Z"
    }
   },
   "source": [
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUmaaCmCprYw"
   },
   "source": [
    "# Downloading the Tanzania Waterpump Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkdEatMkUKa1"
   },
   "source": [
    "Make sure  you only use the dataset that is available through the **DS** **Kaggle Competition**. DO NOT USE any other Tanzania waterpump datasets that you might find online.\n",
    "\n",
    "There are two ways you can get the dataset. Make sure you have joined the competition first!:\n",
    "\n",
    "1. You can download the dataset directly by accessing the challenge and the files through the Kaggle Competition URL on Canvas (make sure you have joined the competition!)\n",
    "\n",
    "2. Use the Kaggle API using the code in the following cells. This article provides helpful information on how to fetch your Kaggle Dataset into Google Colab using the Kaggle API.\n",
    "\n",
    "> https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6TZ5nDFYkCa"
   },
   "source": [
    "# Using Kaggle API to download datset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X2e6fPUATxLZ",
    "outputId": "6495b3e1-9af5-4299-b265-4acc99f18538"
   },
   "source": [
    "# mounting your google drive on colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYSpUv9uYBAo",
    "outputId": "b8e7a8fe-b024-4c72-a8ce-b4a2dae5525d"
   },
   "source": [
    "#change your working directory, if you want to or have already saved your kaggle dataset on google drive.\n",
    "%cd /content/gdrive/My Drive/Kaggle\n",
    "# update it to your folder location on drive that contains the dataset and/or kaggle API token json file."
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/gdrive/My Drive/Kaggle\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dXChvgdZYb_t"
   },
   "source": [
    "# Download your Kaggle Dataset, if you haven't already done so.\n",
    "# import os\n",
    "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
    "# !kaggle competitions download -c bloomtech-water-pump-challenge"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NB84qgRRYdDF"
   },
   "source": [
    "# Unzip your Kaggle dataset, if you haven't already done so.\n",
    "# !unzip \\*.zip  && rm *.zip"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eag2zYiQYf6q",
    "outputId": "b1021e6f-85fa-436f-eade-b5da315e9e19"
   },
   "source": [
    "# List all files in your Kaggle folder on your google drive.\n",
    "!ls"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sample_submission.csv  test_features.csv  train_features.csv  train_labels.csv\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfhziD2Wn_iO"
   },
   "source": [
    "# I. Wrangle Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uYjLLI4ag_Bc"
   },
   "source": [
    "def wrangle(fm_path, tv_path=None):\n",
    "  if tv_path:\n",
    "    df = pd.merge(pd.read_csv(fm_path,\n",
    "                              na_values=[0, -2.000000e-08],\n",
    "                              parse_dates=['date_recorded']),\n",
    "                  pd.read_csv(tv_path)).set_index('id')\n",
    "\n",
    "\n",
    "  else:\n",
    "\n",
    "    df = pd.read_csv(fm_path,\n",
    "                     na_values=[0, -2.000000e-08],\n",
    "                     parse_dates=['date_recorded'],\n",
    "                     index_col='id')\n",
    "\n",
    "\n",
    "  # Drop constant columns\n",
    "  df.drop(columns=['recorded_by'], inplace=True)\n",
    "\n",
    "  # Create age feature\n",
    "  df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
    "  df.drop(columns='date_recorded', inplace=True)\n",
    "\n",
    "  # Drop HCCCs\n",
    "  cutoff = 100\n",
    "  drop_cols = [col for col in df.select_dtypes('object').columns\n",
    "              if df[col].nunique() > cutoff]\n",
    "  df.drop(columns=drop_cols, inplace=True)\n",
    "\n",
    "  # Drop duplicate columns # check for atleast a 100 values\n",
    "  dupe_cols = [col for col in df.head(100).T.duplicated().index\n",
    "               if df.head(100).T.duplicated()[col]]\n",
    "  df.drop(columns=dupe_cols, inplace=True)\n",
    "\n",
    "  return df\n",
    "\n",
    "df = wrangle(fm_path='train_features.csv',\n",
    "             tv_path='train_labels.csv')\n",
    "\n",
    "X_test = wrangle(fm_path='test_features.csv')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni2SLySrZ5ZB"
   },
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Classify into pumps that need repair and pumps that do not need repairs.\n",
    "# functional - class 0\n",
    "# non functional, functional needs repair - class 1"
   ],
   "metadata": {
    "id": "5bd-smZ3rTGD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# OPTION 1\n",
    "np.where(df['status_group']=='functional',0,1)"
   ],
   "metadata": {
    "id": "0wlFRLiTrTBZ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# OPTION 2\n",
    "(df['status_group'] != 'functional').astype(int)"
   ],
   "metadata": {
    "id": "pGBCTAY4rX5S"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# OPTION 3\n",
    "df['status_group'].apply(lambda x: 0 if x=='functional' else 1)"
   ],
   "metadata": {
    "id": "zRW2JXQkrX0k"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dd3R4DDqg-Zc"
   },
   "source": [
    "# II. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KJptRukxgzjH"
   },
   "source": [
    "# Split TV / FM\n",
    "target =\n",
    "X = df.drop(columns=target)\n",
    "y = df[target]\n",
    "\n",
    "# Train-val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Sanity check\n",
    "assert len(X_train) + len(X_val) == len(X)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2-vAPn3hHUc"
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WKceqLphhGoJ"
   },
   "source": [
    "print('Baseline Accuracy:', y_train.value_counts(normalize=True).max())"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fK1_Gn61hJYd"
   },
   "source": [
    "# Build Model\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "EsnnXNnurCo9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vM1rgtDzq2y"
   },
   "source": [
    "# Interlude: Beware or Leakage\n",
    "\n",
    "If you leave `'status_group'` in your feature matrix, you'll have **leakage**."
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "phZNiE8Yq2-x"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ES83EQ7krF-G"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMwEt1k474xc"
   },
   "source": [
    "# Check Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "judyBmufjFMO"
   },
   "source": [
    "**Accuracy Score**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dYfiyggjjHJc"
   },
   "source": [
    "print('Training Accuracy:', model.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model.score(X_val, y_val))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "q0lbIK5sGtaE"
   },
   "source": [
    "print('Training Accuracy:', model.score(X_train, y_train))\n",
    "print('Validation Accuracy:', model.score(X_val, y_val))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYl61hLojcoI"
   },
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GIejjFdRB7nO"
   },
   "source": [
    "plot_confusion_matrix = ConfusionMatrixDisplay.from_estimator"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "g-PNkDJaqyEx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-1W_YipqZRU"
   },
   "source": [
    "**Precision Score**\n",
    "\n",
    "Of all the pumps that you predicted as needing repair, what proportion actually needed repair?"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# precision = tp / (tp + fp)"
   ],
   "metadata": {
    "id": "9n6KnkW8qwaK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "vPy4pV0fqwXB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K7LCntg4r3Dx"
   },
   "source": [
    "**Recall Score**\n",
    "\n",
    "Of those pumps that actually needed repair, what proportion did you correctly predict as needing repair?"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# recall tp/(tp+fn)"
   ],
   "metadata": {
    "id": "V6U_VSUvqv9q"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "BcWG-udxqvfy"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dlUIxr6Qsyto"
   },
   "source": [
    "**Classification Report**"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "6xWoHiYzqtfe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ZFwk8TyzquYJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gY651G8UTz14"
   },
   "source": [
    "# Case Study\n",
    "\n",
    "Let's say that is costs the Tanzanian government $100 to inspect a water pump, and there is only funding for 2000 pump inspections."
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "C-Zd7BTYqq6n"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCEOYhXLT6jU"
   },
   "source": [
    "Scenario 1: Choose pumps randomly"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "QdSCwgzQqr8_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "lV8S_Yclqr2u"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bi3hLi8sbDcS"
   },
   "source": [
    "\n",
    "print('Inspections conducted:',)\n",
    "print('Pumps repaired:', )\n",
    "print('Funds wasted:', )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T1JrG_BEUgCd"
   },
   "source": [
    "Scenario 2: Using our model \"out of the box\""
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data = {\n",
    "    'y_val':y_val,\n",
    "    'y_pred':\n",
    "}\n",
    "\n",
    "results =pd.DataFrame(data)"
   ],
   "metadata": {
    "id": "GDW3853cqlpe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "o64ZB62PqmiX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QFoLTRxocMpw"
   },
   "source": [
    "print('Inspections conducted:',)\n",
    "print('Pumps repaired:',  )\n",
    "print('Funds wasted:',)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sj_80wEQb3N1"
   },
   "source": [
    "Scenario 3: We empasize **precision** in our model, and only select pumps that our model is very certain (`>0.85`) need repair."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yB4jG29FEmUz"
   },
   "source": [
    "data = {\n",
    "    'y_val':y_val,\n",
    "    'y_pred_proba':\n",
    "}\n",
    "\n",
    "results =pd.DataFrame(data)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Im5juTHQqdgb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "A3aN9TD6d0ly"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TC1G1ZmHeVgN"
   },
   "source": [
    "print('Inspections conducted:', )\n",
    "print('Pumps repaired:', )\n",
    "print('Funds wasted:', )\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
