{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Mountain_Scott_LS_DS_221_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/economicactivist/DS-Unit-2-Kaggle-Challenge/blob/master/module1-decision-trees/LS_DS_221_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pKVwa18oP8o",
        "colab_type": "text"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 2, Module 1*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7IXUfiQ2UKj6"
      },
      "source": [
        "# Decision Trees\n",
        "\n",
        "## Assignment\n",
        "- [ ] [Sign up for a Kaggle account](https://www.kaggle.com/), if you don’t already have one. Go to our Kaggle InClass competition website. You will be given the URL in Slack. Go to the Rules page. Accept the rules of the competition. Notice that the Rules page also has instructions for the Submission process. The Data page has feature definitions.\n",
        "- [ ] Do train/validate/test split with the Tanzania Waterpumps data.\n",
        "- [ ] Begin with baselines for classification.\n",
        "- [ ] Select features. Use a scikit-learn pipeline to encode categoricals, impute missing values, and fit a decision tree classifier.\n",
        "- [ ] Get your validation accuracy score.\n",
        "- [ ] Get and plot your feature importances.\n",
        "- [ ] Submit your predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file. Or you can use the Kaggle API to submit your predictions.)\n",
        "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
        "\n",
        "\n",
        "## Stretch Goals\n",
        "\n",
        "### Reading\n",
        "\n",
        "- A Visual Introduction to Machine Learning\n",
        "  - [Part 1: A Decision Tree](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/)\n",
        "  - [Part 2: Bias and Variance](http://www.r2d3.us/visual-intro-to-machine-learning-part-2/)\n",
        "- [Decision Trees: Advantages & Disadvantages](https://christophm.github.io/interpretable-ml-book/tree.html#advantages-2)\n",
        "- [How a Russian mathematician constructed a decision tree — by hand — to solve a medical problem](http://fastml.com/how-a-russian-mathematician-constructed-a-decision-tree-by-hand-to-solve-a-medical-problem/)\n",
        "- [How decision trees work](https://brohrer.github.io/how_decision_trees_work.html)\n",
        "- [Let’s Write a Decision Tree Classifier from Scratch](https://www.youtube.com/watch?v=LDRbO9a6XPU) — _Don’t worry about understanding the code, just get introduced to the concepts. This 10 minute video has excellent diagrams and explanations._\n",
        "- [Random Forests for Complete Beginners: The definitive guide to Random Forests and Decision Trees](https://victorzhou.com/blog/intro-to-random-forests/)\n",
        "\n",
        "\n",
        "### Doing\n",
        "- [ ] Add your own stretch goal(s) !\n",
        "- [ ] Define a function to wrangle train, validate, and test sets in the same way. Clean outliers and engineer features. (For example, [what columns have zeros and shouldn't?](https://github.com/Quartz/bad-data-guide#zeros-replace-missing-values) What columns are duplicates, or nearly duplicates? Can you extract the year from date_recorded? Can you engineer new features, such as the number of years from waterpump construction to waterpump inspection?)\n",
        "- [ ] Try other [scikit-learn imputers](https://scikit-learn.org/stable/modules/impute.html).\n",
        "- [ ] Make exploratory visualizations and share on Slack.\n",
        "\n",
        "\n",
        "#### Exploratory visualizations\n",
        "\n",
        "Visualize the relationships between feature(s) and target. I recommend you do this with your training set, after splitting your data. \n",
        "\n",
        "For this problem, you may want to create a new column to represent the target as a number, 0 or 1. For example:\n",
        "\n",
        "```python\n",
        "train['functional'] = (train['status_group']=='functional').astype(int)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "You can try [Seaborn \"Categorical estimate\" plots](https://seaborn.pydata.org/tutorial/categorical.html) for features with reasonably few unique values. (With too many unique values, the plot is unreadable.)\n",
        "\n",
        "- Categorical features. (If there are too many unique values, you can replace less frequent values with \"OTHER.\")\n",
        "- Numeric features. (If there are too many unique values, you can [bin with pandas cut / qcut functions](https://pandas.pydata.org/pandas-docs/stable/getting_started/basics.html?highlight=qcut#discretization-and-quantiling).)\n",
        "\n",
        "You can try [Seaborn linear model plots](https://seaborn.pydata.org/tutorial/regression.html) with numeric features. For this classification problem, you may want to use the parameter `logistic=True`, but it can be slow.\n",
        "\n",
        "You do _not_ need to use Seaborn, but it's nice because it includes confidence intervals to visualize uncertainty.\n",
        "\n",
        "#### High-cardinality categoricals\n",
        "\n",
        "This code from a previous assignment demonstrates how to replace less frequent values with 'OTHER'\n",
        "\n",
        "```python\n",
        "# Reduce cardinality for NEIGHBORHOOD feature ...\n",
        "\n",
        "# Get a list of the top 10 neighborhoods\n",
        "top10 = train['NEIGHBORHOOD'].value_counts()[:10].index\n",
        "\n",
        "# At locations where the neighborhood is NOT in the top 10,\n",
        "# replace the neighborhood with 'OTHER'\n",
        "train.loc[~train['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "test.loc[~test['NEIGHBORHOOD'].isin(top10), 'NEIGHBORHOOD'] = 'OTHER'\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9eSnDYhUGD7",
        "outputId": "23b26241-5289-4b22-d3f3-274376788dfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "    !pip install pandas-profiling==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders==2.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/52/c54191ad3782de633ea3d6ee3bb2837bda0cf3bc97644bb6375cf14150a0/category_encoders-2.1.0-py2.py3-none-any.whl (100kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 24.5MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 30kB 3.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 71kB 4.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 81kB 3.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 92kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 3.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.10.2)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.22.1)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from category_encoders==2.*) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.4.1->category_encoders==2.*) (1.12.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders==2.*) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders==2.*) (2018.9)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.1.0\n",
            "Collecting pandas-profiling==2.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/b0/bd5e3aaf37302fbe581b6947dc5ec1cda02a0ffe50fc823123def73e4d7a/pandas-profiling-2.5.0.tar.gz (192kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.17.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.4.1)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.25.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (3.1.3)\n",
            "Collecting confuse==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/4c/6f/90e860cba937c174d8b3775729ccc6377eb91f52ad4eeb008e7252a3646d/confuse-1.0.0.tar.gz\n",
            "Requirement already satisfied: jinja2==2.11.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (2.11.1)\n",
            "Collecting visions==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/07/4a/ab37f8bafda516b66c4f475b221a6c170097c0db203750a4aafb01023339/visions-0.2.2.tar.gz\n",
            "Collecting htmlmin==0.1.12\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/e7/fcd59e12169de19f0131ff2812077f964c6b960e7c09804d30a7bf2ab461/htmlmin-0.1.12.tar.gz\n",
            "Requirement already satisfied: missingno==0.4.2 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (0.4.2)\n",
            "Collecting phik==0.9.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/cf/b8cef2778104dc5d319f36dd836efaceb07a037cbf63f27c966b5a193ce9/phik-0.9.9-py3-none-any.whl (607kB)\n",
            "\u001b[K     |████████████████████████████████| 614kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: astropy>=3.2.3 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (4.0)\n",
            "Collecting tangled-up-in-unicode==0.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/fc/e3c970c5007b405827a4623e70fc4eb966ee49bc1edbd56c33e85e1c6534/tangled_up_in_unicode-0.0.3.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 12.9MB/s \n",
            "\u001b[?25hCollecting tqdm==4.42.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/2e/4307206db63f05ed37e21d4c0d843d0fbcacd62479f8ce99ba0f2c0875e0/tqdm-4.42.0-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 9.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: kaggle==1.5.6 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (1.5.6)\n",
            "Requirement already satisfied: ipywidgets==7.5.1 in /usr/local/lib/python3.6/dist-packages (from pandas-profiling==2.*) (7.5.1)\n",
            "Collecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->pandas-profiling==2.*) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->pandas-profiling==2.*) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->pandas-profiling==2.*) (2.4.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->pandas-profiling==2.*) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.0.3->pandas-profiling==2.*) (0.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from confuse==1.0.0->pandas-profiling==2.*) (3.13)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2==2.11.1->pandas-profiling==2.*) (1.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from visions==0.2.2->pandas-profiling==2.*) (2.4)\n",
            "Collecting attr\n",
            "  Downloading https://files.pythonhosted.org/packages/de/be/ddc7f84d4e087144472a38a373d3e319f51a6faf6e5fc1ae897173675f21/attr-0.3.1.tar.gz\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from missingno==0.4.2->pandas-profiling==2.*) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.6/dist-packages (from phik==0.9.9->pandas-profiling==2.*) (0.14.1)\n",
            "Collecting pytest-pylint>=0.13.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0f/2e/12d3e83e90341fc7aff0e42955ab560df4e7f07b847f98302e23eba96289/pytest_pylint-0.15.0-py3-none-any.whl\n",
            "Requirement already satisfied: nbconvert>=5.3.1 in /usr/local/lib/python3.6/dist-packages (from phik==0.9.9->pandas-profiling==2.*) (5.6.1)\n",
            "Requirement already satisfied: jupyter-client>=5.2.3 in /usr/local/lib/python3.6/dist-packages (from phik==0.9.9->pandas-profiling==2.*) (5.3.4)\n",
            "Requirement already satisfied: numba>=0.38.1 in /usr/local/lib/python3.6/dist-packages (from phik==0.9.9->pandas-profiling==2.*) (0.47.0)\n",
            "Collecting pytest>=4.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/c0/34033b2df7718b91c667bd259d5ce632ec3720198b7068c0ba6f6104ff89/pytest-5.3.5-py3-none-any.whl (235kB)\n",
            "\u001b[K     |████████████████████████████████| 235kB 28.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6->pandas-profiling==2.*) (1.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6->pandas-profiling==2.*) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6->pandas-profiling==2.*) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6->pandas-profiling==2.*) (4.0.0)\n",
            "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (5.5.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (5.0.4)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (3.5.1)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (4.3.3)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.6/dist-packages (from ipywidgets==7.5.1->pandas-profiling==2.*) (4.6.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->pandas-profiling==2.*) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->pandas-profiling==2.*) (2.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=3.0.3->pandas-profiling==2.*) (45.1.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->visions==0.2.2->pandas-profiling==2.*) (4.4.1)\n",
            "Collecting pylint>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e9/59/43fc36c5ee316bb9aeb7cf5329cdbdca89e5749c34d5602753827c0aa2dc/pylint-2.4.4-py3-none-any.whl (302kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 29.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.6.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.3)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.4.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (1.4.2)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (4.6.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (2.1.3)\n",
            "Requirement already satisfied: tornado>=4.1 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik==0.9.9->pandas-profiling==2.*) (4.5.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client>=5.2.3->phik==0.9.9->pandas-profiling==2.*) (17.0.0)\n",
            "Requirement already satisfied: llvmlite>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.38.1->phik==0.9.9->pandas-profiling==2.*) (0.31.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (19.3.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (8.2.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/a0/28/85c7aa31b80d150b772fbe4a229487bc6644da9ccb7e427dd8cc60cb8a62/pluggy-0.13.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (1.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (0.1.8)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (20.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (1.5.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6->pandas-profiling==2.*) (1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (1.0.18)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (4.8.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->pandas-profiling==2.*) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets==7.5.1->pandas-profiling==2.*) (0.2.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets==7.5.1->pandas-profiling==2.*) (5.2.2)\n",
            "Collecting astroid<2.4,>=2.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/ae/86734823047962e7b8c8529186a1ac4a7ca19aaf1aa0c7713c022ef593fd/astroid-2.3.3-py3-none-any.whl (205kB)\n",
            "\u001b[K     |████████████████████████████████| 215kB 36.6MB/s \n",
            "\u001b[?25hCollecting isort<5,>=4.2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/b0/c121fd1fa3419ea9bfd55c7f9c4fedfec5143208d8c7ad3ce3db6c623c21/isort-4.3.21-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.7MB/s \n",
            "\u001b[?25hCollecting mccabe<0.7,>=0.6\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert>=5.3.1->phik==0.9.9->pandas-profiling==2.*) (0.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=4.0.2->phik==0.9.9->pandas-profiling==2.*) (2.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets==7.5.1->pandas-profiling==2.*) (0.6.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets==7.5.1->pandas-profiling==2.*) (0.8.3)\n",
            "Collecting lazy-object-proxy==1.4.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0b/dd/b1e3407e9e6913cf178e506cd0dee818e58694d9a5cd1984e3f6a8b9a10f/lazy_object_proxy-1.4.3-cp36-cp36m-manylinux1_x86_64.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 11.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt==1.11.* in /usr/local/lib/python3.6/dist-packages (from astroid<2.4,>=2.3.0->pylint>=2.0.0->pytest-pylint>=0.13.0->phik==0.9.9->pandas-profiling==2.*) (1.11.2)\n",
            "Collecting typed-ast<1.5,>=1.4.0; implementation_name == \"cpython\" and python_version < \"3.8\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/ed/5459080d95eb87a02fe860d447197be63b6e2b5e9ff73c2b0a85622994f4/typed_ast-1.4.1-cp36-cp36m-manylinux1_x86_64.whl (737kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 39.5MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pandas-profiling, confuse, visions, htmlmin, tangled-up-in-unicode, attr\n",
            "  Building wheel for pandas-profiling (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas-profiling: filename=pandas_profiling-2.5.0-py2.py3-none-any.whl size=241329 sha256=0ad74e2cce3ed1e6580f34ff50f1b95a62d48c699a0fd169ffa67ac01a7021c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/c9/f1/4a2f30c760e017f3e2f46be999c4597a93d126ef5ea38e276f\n",
            "  Building wheel for confuse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for confuse: filename=confuse-1.0.0-cp36-none-any.whl size=17487 sha256=0e33e5ed7253feb28b33dfde748114c88ca0783e7e9fbe290f54d49e20017d93\n",
            "  Stored in directory: /root/.cache/pip/wheels/b0/b2/96/2074eee7dbf7b7df69d004c9b6ac4e32dad04fb7666cf943bd\n",
            "  Building wheel for visions (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visions: filename=visions-0.2.2-cp36-none-any.whl size=53058 sha256=e6de7843ebda5b1de8dae4f2856f42b273b6488af03944761aa1ed59d384ed83\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/87/68/294a9e88d82e395b38571df18f7cb71e9ab51cedae77dd6f31\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-cp36-none-any.whl size=27084 sha256=7e08efa7e9f0d7c97b4e207c4c98b72a7eaf739ffcb1de9f4e1e0a1e09adb0dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/07/ac/7c5a9d708d65247ac1f94066cf1db075540b85716c30255459\n",
            "  Building wheel for tangled-up-in-unicode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tangled-up-in-unicode: filename=tangled_up_in_unicode-0.0.3-cp36-none-any.whl size=1554154 sha256=8cb83c352b14521c5d94d72fe206baa47032fc92dde3478faf99e9f7064edb37\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/57/cc/5f58206efb00418d4dcae8d08a3cb40627778ea29622f664c6\n",
            "  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attr: filename=attr-0.3.1-cp36-none-any.whl size=2459 sha256=a5f6c64ca2081dd0cd88e88ed7d31fb0df379afd57385f13937bbcd69211d6cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/96/9b/1f8892a707d17095b5a6eab0275da9d39e68e03a26aee2e726\n",
            "Successfully built pandas-profiling confuse visions htmlmin tangled-up-in-unicode attr\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: confuse, tangled-up-in-unicode, attr, visions, htmlmin, pluggy, pytest, lazy-object-proxy, typed-ast, astroid, isort, mccabe, pylint, pytest-pylint, phik, tqdm, requests, pandas-profiling\n",
            "  Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Found existing installation: tqdm 4.28.1\n",
            "    Uninstalling tqdm-4.28.1:\n",
            "      Successfully uninstalled tqdm-4.28.1\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "  Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "Successfully installed astroid-2.3.3 attr-0.3.1 confuse-1.0.0 htmlmin-0.1.12 isort-4.3.21 lazy-object-proxy-1.4.3 mccabe-0.6.1 pandas-profiling-2.5.0 phik-0.9.9 pluggy-0.13.1 pylint-2.4.4 pytest-5.3.5 pytest-pylint-0.15.0 requests-2.22.0 tangled-up-in-unicode-0.0.3 tqdm-4.42.0 typed-ast-1.4.1 visions-0.2.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QJBD4ruICm1m",
        "outputId": "f30a0dfa-d131-46a2-f305-5a63eefa3f6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train = pd.merge(pd.read_csv(DATA_PATH+'waterpumps/train_features.csv'), \n",
        "                 pd.read_csv(DATA_PATH+'waterpumps/train_labels.csv'))\n",
        "test = pd.read_csv(DATA_PATH+'waterpumps/test_features.csv')\n",
        "sample_submission = pd.read_csv(DATA_PATH+'waterpumps/sample_submission.csv')\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 41), (14358, 40))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8o35EH48oP84",
        "colab_type": "code",
        "outputId": "3d848257-312b-480a-a437-16907e3b8bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Check Pandas Profiling version\n",
        "import pandas_profiling\n",
        "pandas_profiling.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2Amxyx3xphbb",
        "colab": {}
      },
      "source": [
        "# Old code for Pandas Profiling version 2.3\n",
        "# It can be very slow with medium & large datasets.\n",
        "# These parameters will make it faster.\n",
        "\n",
        "# profile = train.profile_report(\n",
        "#     check_correlation_pearson=False,\n",
        "#     correlations={\n",
        "#         'pearson': False,\n",
        "#         'spearman': False,\n",
        "#         'kendall': False,\n",
        "#         'phi_k': False,\n",
        "#         'cramers': False,\n",
        "#         'recoded': False,\n",
        "#     },\n",
        "#     plot={'histogram': {'bayesian_blocks_bins': False}},\n",
        "# )\n",
        "#\n",
        "\n",
        "# New code for Pandas Profiling version 2.4\n",
        "# from pandas_profiling import ProfileReport\n",
        "# profile = ProfileReport(train, minimal=True).to_notebook_iframe()\n",
        "\n",
        "# profile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGmQ6zNQ6Shn",
        "colab_type": "text"
      },
      "source": [
        "Features\n",
        "Your goal is to predict the operating condition of a waterpoint for each record in the dataset. You are provided the following set of information about the waterpoints:\n",
        "\n",
        "amount_tsh : Total static head (amount water available to waterpoint)\n",
        "date_recorded : The date the row was entered\n",
        "funder : Who funded the well\n",
        "gps_height : Altitude of the well\n",
        "installer : Organization that installed the well\n",
        "longitude : GPS coordinate\n",
        "latitude : GPS coordinate\n",
        "wpt_name : Name of the waterpoint if there is one\n",
        "num_private :\n",
        "basin : Geographic water basin\n",
        "subvillage : Geographic location\n",
        "region : Geographic location\n",
        "region_code : Geographic location (coded)\n",
        "district_code : Geographic location (coded)\n",
        "lga : Geographic location\n",
        "ward : Geographic location\n",
        "population : Population around the well\n",
        "public_meeting : True/False\n",
        "recorded_by : Group entering this row of data\n",
        "scheme_management : Who operates the waterpoint\n",
        "scheme_name : Who operates the waterpoint\n",
        "permit : If the waterpoint is permitted\n",
        "construction_year : Year the waterpoint was constructed\n",
        "extraction_type : The kind of extraction the waterpoint uses\n",
        "extraction_type_group : The kind of extraction the waterpoint uses\n",
        "extraction_type_class : The kind of extraction the waterpoint uses\n",
        "management : How the waterpoint is managed\n",
        "management_group : How the waterpoint is managed\n",
        "payment : What the water costs\n",
        "payment_type : What the water costs\n",
        "water_quality : The quality of the water\n",
        "quality_group : The quality of the water\n",
        "quantity : The quantity of water\n",
        "quantity_group : The quantity of water\n",
        "source : The source of the water\n",
        "source_type : The source of the water\n",
        "source_class : The source of the water\n",
        "waterpoint_type : The kind of waterpoint\n",
        "waterpoint_type_group : The kind of waterpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTHQGRohoP9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPnUgpszMpA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKsN9kpsBBDf",
        "colab_type": "code",
        "outputId": "2f3dd549-d631-4b53-ec95-3e7ebd81a296",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['id', 'amount_tsh', 'date_recorded', 'funder', 'gps_height',\n",
              "       'installer', 'longitude', 'latitude', 'wpt_name', 'num_private',\n",
              "       'basin', 'subvillage', 'region', 'region_code', 'district_code', 'lga',\n",
              "       'ward', 'population', 'public_meeting', 'recorded_by',\n",
              "       'scheme_management', 'scheme_name', 'permit', 'construction_year',\n",
              "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
              "       'management', 'management_group', 'payment', 'payment_type',\n",
              "       'water_quality', 'quality_group', 'quantity', 'quantity_group',\n",
              "       'source', 'source_type', 'source_class', 'waterpoint_type',\n",
              "       'waterpoint_type_group', 'status_group'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiuoE_xzBBHD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cols_to_keep = ['id','funder',\n",
        "       'installer', \n",
        "       'basin', 'subvillage', 'region', 'population', \n",
        "      'permit', \n",
        "       'extraction_type', 'extraction_type_group', 'extraction_type_class',\n",
        "       'management', 'management_group', 'payment', \n",
        "        'quality_group','quantity_group',\n",
        "       'source',  'source_class', \n",
        "       'waterpoint_type_group', 'status_group']   #gps_height (median impute? or drop?) 'longitude', 'latitude', "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkMCRdSKKmDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldq2sF_rKmZe",
        "colab_type": "text"
      },
      "source": [
        "I dropped 18 columns in total"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX6saA22vaH4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_train_cols_to_keep = cols_to_keep[1:]\n",
        "test_id_col=test.id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ9-ZIz_YNSG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0CzwyzaI_TR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = train[test_train_cols_to_keep]\n",
        "test_train_cols_to_keep.pop()\n",
        "test = test[test_train_cols_to_keep] \n",
        " # maintaining the same dimensions for train and test sets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZY3Co5j0h_c",
        "colab_type": "code",
        "outputId": "c4eb1bd4-f8d2-4fac-fba3-5746eb934bb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "source": [
        "test"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>funder</th>\n",
              "      <th>installer</th>\n",
              "      <th>basin</th>\n",
              "      <th>subvillage</th>\n",
              "      <th>region</th>\n",
              "      <th>population</th>\n",
              "      <th>permit</th>\n",
              "      <th>extraction_type</th>\n",
              "      <th>extraction_type_group</th>\n",
              "      <th>extraction_type_class</th>\n",
              "      <th>management</th>\n",
              "      <th>management_group</th>\n",
              "      <th>payment</th>\n",
              "      <th>quality_group</th>\n",
              "      <th>quantity_group</th>\n",
              "      <th>source</th>\n",
              "      <th>source_class</th>\n",
              "      <th>waterpoint_type_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dmdd</td>\n",
              "      <td>DMDD</td>\n",
              "      <td>Internal</td>\n",
              "      <td>Magoma</td>\n",
              "      <td>Manyara</td>\n",
              "      <td>321</td>\n",
              "      <td>True</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>parastatal</td>\n",
              "      <td>parastatal</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Government Of Tanzania</td>\n",
              "      <td>DWE</td>\n",
              "      <td>Pangani</td>\n",
              "      <td>Kimnyak</td>\n",
              "      <td>Arusha</td>\n",
              "      <td>300</td>\n",
              "      <td>True</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Internal</td>\n",
              "      <td>Msatu</td>\n",
              "      <td>Singida</td>\n",
              "      <td>500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Finn Water</td>\n",
              "      <td>FINN WATER</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Kipindimbi</td>\n",
              "      <td>Lindi</td>\n",
              "      <td>250</td>\n",
              "      <td>True</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>other</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>unknown</td>\n",
              "      <td>good</td>\n",
              "      <td>dry</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>other</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bruder</td>\n",
              "      <td>BRUDER</td>\n",
              "      <td>Ruvuma / Southern Coast</td>\n",
              "      <td>Losonga</td>\n",
              "      <td>Ruvuma</td>\n",
              "      <td>60</td>\n",
              "      <td>True</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>water board</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay monthly</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14353</th>\n",
              "      <td>Danida</td>\n",
              "      <td>Da</td>\n",
              "      <td>Wami / Ruvu</td>\n",
              "      <td>Yombo</td>\n",
              "      <td>Pwani</td>\n",
              "      <td>20</td>\n",
              "      <td>True</td>\n",
              "      <td>mono</td>\n",
              "      <td>mono</td>\n",
              "      <td>motorpump</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>river</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14354</th>\n",
              "      <td>Hiap</td>\n",
              "      <td>HIAP</td>\n",
              "      <td>Pangani</td>\n",
              "      <td>Mkondoa</td>\n",
              "      <td>Tanga</td>\n",
              "      <td>2960</td>\n",
              "      <td>False</td>\n",
              "      <td>nira/tanira</td>\n",
              "      <td>nira/tanira</td>\n",
              "      <td>handpump</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>pay annually</td>\n",
              "      <td>salty</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>hand pump</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14355</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Internal</td>\n",
              "      <td>Juhudi</td>\n",
              "      <td>Singida</td>\n",
              "      <td>200</td>\n",
              "      <td>NaN</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>dam</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14356</th>\n",
              "      <td>Germany</td>\n",
              "      <td>DWE</td>\n",
              "      <td>Lake Nyasa</td>\n",
              "      <td>Namakinga B</td>\n",
              "      <td>Ruvuma</td>\n",
              "      <td>150</td>\n",
              "      <td>True</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>river</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14357</th>\n",
              "      <td>Government Of Tanzania</td>\n",
              "      <td>Government</td>\n",
              "      <td>Lake Nyasa</td>\n",
              "      <td>Kamba</td>\n",
              "      <td>Ruvuma</td>\n",
              "      <td>40</td>\n",
              "      <td>True</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>gravity</td>\n",
              "      <td>vwc</td>\n",
              "      <td>user-group</td>\n",
              "      <td>never pay</td>\n",
              "      <td>good</td>\n",
              "      <td>dry</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14358 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       funder   installer  ... source_class waterpoint_type_group\n",
              "0                        Dmdd        DMDD  ...      surface                 other\n",
              "1      Government Of Tanzania         DWE  ...  groundwater    communal standpipe\n",
              "2                         NaN         NaN  ...      surface                 other\n",
              "3                  Finn Water  FINN WATER  ...  groundwater                 other\n",
              "4                      Bruder      BRUDER  ...  groundwater    communal standpipe\n",
              "...                       ...         ...  ...          ...                   ...\n",
              "14353                  Danida          Da  ...      surface    communal standpipe\n",
              "14354                    Hiap        HIAP  ...  groundwater             hand pump\n",
              "14355                     NaN         NaN  ...      surface    communal standpipe\n",
              "14356                 Germany         DWE  ...      surface    communal standpipe\n",
              "14357  Government Of Tanzania  Government  ...  groundwater    communal standpipe\n",
              "\n",
              "[14358 rows x 18 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kd50Y41OBBLe",
        "colab_type": "code",
        "outputId": "579f204b-be39-4315-d47a-c531f61d383a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 19), (14358, 18))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmLe3xQWBBPq",
        "colab_type": "code",
        "outputId": "ba522c34-783b-43d6-929d-b1a7ca463cff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape, test.shape  #1812 rows removed\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((59400, 19), (14358, 18))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pK45UPZEM4dE",
        "colab_type": "code",
        "outputId": "948b8160-b0a3-4a54-e858-c12dbabe4189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train.funder.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Government Of Tanzania    9084\n",
              "Danida                    3114\n",
              "Hesawa                    2202\n",
              "Rwssp                     1374\n",
              "World Bank                1349\n",
              "                          ... \n",
              "Maajabu Pima                 1\n",
              "Unhcr/government             1\n",
              "Maashumu Mohamed             1\n",
              "Ngumi                        1\n",
              "Muhindi                      1\n",
              "Name: funder, Length: 1897, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AA4ZFIv-KAil",
        "colab_type": "code",
        "outputId": "58f77e7b-4da3-4e04-f19c-c0dd134b7358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train.funder = train.funder.fillna(\"Government Of Tanzania\")\n",
        "train.installer = train.installer.fillna(\"DWE\")\n",
        "train.subvillage = train.subvillage.fillna(\"Majengo\")\n",
        "\n",
        "train.funder.value_counts()\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Government Of Tanzania    12719\n",
              "Danida                     3114\n",
              "Hesawa                     2202\n",
              "Rwssp                      1374\n",
              "World Bank                 1349\n",
              "                          ...  \n",
              "Maajabu Pima                  1\n",
              "Unhcr/government              1\n",
              "Maashumu Mohamed              1\n",
              "Ngumi                         1\n",
              "Muhindi                       1\n",
              "Name: funder, Length: 1897, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GN_rGt2oSKJq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def reduce_categories(df, list_of_series, list_of_thresholds):\n",
        "#   a=[]\n",
        "#   for i in range(len(list_of_series)):\n",
        "#     series = df[list_of_series[i]]\n",
        "#     series_frequencies = series.value_counts(normalize=True)\n",
        "#     threshold = list_of_thresholds[i]\n",
        "#     smaller_categories = series_frequencies[series_frequencies<threshold].index\n",
        "#     reduced_series = df[series].replace(smaller_categories, \"Other\")\n",
        "#     a.append(reduced_series)\n",
        "#   return a\n",
        "\n",
        "# reduce_categories(train, ['funder', 'installer', 'subvillage'], [.01,.01,.001])\n",
        "\n",
        "\n",
        "funder_frequencies = train.funder.value_counts(normalize=True) # < .01\n",
        "installer_frequencies = train.installer.value_counts(normalize=True) # < .01\n",
        "subvillage_frequencies = train.subvillage.value_counts(normalize=True) # < .001\n",
        "\n",
        "funder_small_categories = funder_frequencies[funder_frequencies < 0.01].index #(returns list of relevant row names)\n",
        "installer_small_categories = installer_frequencies[installer_frequencies < 0.01].index #(returns list of relevant row names)\n",
        "subvillage_small_categories = subvillage_frequencies[subvillage_frequencies < 0.001].index #(returns list of relevant row names)\n",
        "\n",
        "train.funder = train.funder.replace(funder_small_categories, \"Other\")\n",
        "train.installer = train.installer.replace(installer_small_categories, \"Other\")\n",
        "train.subvillage = train.subvillage.replace(subvillage_small_categories, \"Other\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPCrt1Sbbrap",
        "colab_type": "code",
        "outputId": "db463b00-e06b-4d44-c066-17bda87d2c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.population.median()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfvN-g-zbwBs",
        "colab_type": "code",
        "outputId": "81d4095b-75fe-4e82-aae1-5a239d336162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "((train.population==0).sum())/train.shape[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.35994949494949496"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjn274C1ZlHB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "median_population = train.population.median()\n",
        "\n",
        "train.population =  train.population.replace(0, median_population)\n",
        "test.population =  test.population.replace(0, median_population)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94VdmzqfcUwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.permit = train.permit.fillna(False)\n",
        "test.permit = test.permit.fillna(False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cU8fXhAc5vs",
        "colab_type": "code",
        "outputId": "a19b6911-6c84-4e1a-8575-e9eb1c576a1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train.source_class.value_counts(normalize=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "groundwater    0.770943\n",
              "surface        0.224377\n",
              "unknown        0.004680\n",
              "Name: source_class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSgy-XZJdfmk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.source_class = train.source_class.replace(\"unknown\", \"groundwater\")\n",
        "test.source_class = test.source_class.replace(\"unknown\", \"groundwater\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqFj4t6vdlxm",
        "colab_type": "code",
        "outputId": "83a4ffa4-be3c-41d1-f238-85c708b616fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train.source_class.value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "groundwater    46072\n",
              "surface        13328\n",
              "Name: source_class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1TCNpheXyS",
        "colab_type": "text"
      },
      "source": [
        "Come back to this later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp7QKwCUBBa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train.construction_year.value_counts(normalize=True)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHegC8-uBBd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# numeric_train = train.select_dtypes(include=\"number\")\n",
        "# numeric_test = test.select_dtypes(include=\"number\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YS94cJ1BBBh0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# non_numeric_train = train.select_dtypes(exclude=\"number\")\n",
        "# non_numeric_test = test.select_dtypes(exclude=\"number\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOwZAN3cBBls",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(train.shape[1] == (non_numeric_train.shape[1]+numeric_train.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFh7ji5zjq4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#(test.shape[1] == (non_numeric_test.shape[1]+numeric_test.shape[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgXNMCPMkc0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = train.status_group\n",
        "X = train.drop(y.name, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64j5lBVfgtfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1CikpS6kzWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_validate, y_train, y_validate = train_test_split(X,y,test_size=0.2, random_state=99)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EQWmQhzlP9i",
        "colab_type": "text"
      },
      "source": [
        "Test for \"stratify = y\" later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zpi-bV70gtzB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install git+https://github.com/MaxHalford/Prince\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGp4qeNibLwG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from prince import MCA\n",
        "#from sklearn.linear_model import LogisticRegressionCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03N0bOdXcoNP",
        "colab_type": "code",
        "outputId": "5256c706-4b90-4a07-814a-8ffa21400d8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59400, 19)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKr43eZKDgW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install catboost\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWifBeUcgta7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from category_encoders import OneHotEncoder, CatBoostEncoder, OrdinalEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "#from catboost import CatBoostClassifier\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_djh78FJSgi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_latitude_positive = X_train.latitude.apply(abs)\n",
        "# X_longitude_positive = X_train.longitude.apply(abs)\n",
        "\n",
        "# X_train_positive = X_train.copy()\n",
        "\n",
        "# X_train_positive.latitude = X_latitude_positive\n",
        "# X_train_positive.longitude = X_longitude_positive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvk4g5zaEs_8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# mca = MCA()\n",
        "# mca.fit(X_train_positive.select_dtypes(exclude=\"number\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujyQiuwIaWl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from catboost import Pool\n",
        "\n",
        "# train_data = X_train\n",
        "# eval_data = y_train\n",
        "# cat_features = X_train.select_dtypes(include=\"object\").columns.to_list()\n",
        "\n",
        "\n",
        "\n",
        "# train_dataset = Pool(data=X_train,\n",
        "#                      label=y_train,\n",
        "#                      cat_features=cat_features)\n",
        "\n",
        "# eval_dataset = Pool(data=X_validate,\n",
        "#                     label=y_validate,\n",
        "#                     cat_features=cat_features)\n",
        "\n",
        "# # Initialize CatBoostClassifier\n",
        "# model = CatBoostClassifier(iterations=10,\n",
        "#                            learning_rate=.5,\n",
        "#                            depth=16,\n",
        "#                            loss_function='MultiClass')\n",
        "# # Fit model\n",
        "# model.fit(train_dataset)\n",
        "# # Get predicted classes\n",
        "# preds_class = model.predict(eval_dataset)\n",
        "# # Get predicted probabilities for each class\n",
        "# preds_proba = model.predict_proba(eval_dataset)\n",
        "# # Get predicted RawFormulaVal\n",
        "# preds_raw = model.predict(eval_dataset, \n",
        "#                           prediction_type='RawFormulaVal')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDMm5bEWgtqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.score(X_validate,y_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxnRbXEqfpzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pd.DataFrame(preds_class)[0].unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwMRR9eHdb9D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pd.DataFrame(preds_proba, columns=['functional', 'non functional', 'functional needs repair'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_fPAyzogKCU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxeLzzmAhNis",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pipeline = make_pipeline(OrdinalEncoder(),\n",
        "                         RandomForestClassifier(max_depth=50))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ei5ge8qOgtks",
        "colab_type": "code",
        "outputId": "0ce1cc69-6ba1-4548-8a06-e163086a397c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'installer', 'basin',\n",
              "                                      'subvillage', 'region', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'management_group', 'payment',\n",
              "                                      'quality_group', 'quantity_group',\n",
              "                                      'source', 'source_class',\n",
              "                                      'waterpoint_type_group'],\n",
              "                                drop_invariant=False, handle_missing='value...\n",
              "                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                        class_weight=None, criterion='gini',\n",
              "                                        max_depth=50, max_features='auto',\n",
              "                                        max_leaf_nodes=None, max_samples=None,\n",
              "                                        min_impurity_decrease=0.0,\n",
              "                                        min_impurity_split=None,\n",
              "                                        min_samples_leaf=1, min_samples_split=2,\n",
              "                                        min_weight_fraction_leaf=0.0,\n",
              "                                        n_estimators=100, n_jobs=None,\n",
              "                                        oob_score=False, random_state=None,\n",
              "                                        verbose=0, warm_start=False))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arVdcq-1mFm1",
        "colab_type": "code",
        "outputId": "f86dd540-65fb-4cb2-c857-46fa0650b7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Validation Accuracy', pipeline.score(X_validate, y_validate))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7734848484848484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhqH6SmIgtuZ",
        "colab_type": "code",
        "outputId": "de7a6f84-9bd4-43d5-c0e4-a3a1cc08ee8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "pipeline.predict(test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['functional', 'functional', 'functional', ..., 'functional',\n",
              "       'functional', 'non functional'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z6I2ENMbaQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIXlwjyxsiyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Combined_X = X_train.append(X_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbOaTgfOsyg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Combined_y = y_train.append(y_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DEaDzpPgt3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import RandomizedSearchCV\n",
        "# # Number of trees in random forest\n",
        "# n_estimators = [int(x) for x in np.linspace(start = 100, stop = 800, num = 10)]\n",
        "# # Number of features to consider at every split\n",
        "# max_features = ['auto', 'sqrt']\n",
        "# # Maximum number of levels in tree\n",
        "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "# max_depth.append(None)\n",
        "# # Minimum number of samples required to split a node\n",
        "# min_samples_split = [3, 5, 10]\n",
        "# # Minimum number of samples required at each leaf node\n",
        "# min_samples_leaf = [1, 2, 4]\n",
        "# # Method of selecting samples for training each tree\n",
        "# bootstrap = [True, False]\n",
        "# # Create the random grid\n",
        "# random_grid = {'n_estimators': n_estimators,\n",
        "#                'max_features': max_features,\n",
        "#                'max_depth': max_depth,\n",
        "#                'min_samples_split': min_samples_split,\n",
        "#                'min_samples_leaf': min_samples_leaf,\n",
        "#                'bootstrap': bootstrap}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q7gILWGgt7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rf = RandomForestClassifier()\n",
        "# # Random search of parameters, using 3 fold cross validation, \n",
        "# # search across 100 different combinations, and use all available cores\n",
        "# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 6, cv = 4, verbose=2, random_state=42, n_jobs = -1)\n",
        "# # Fit the random search model\n",
        "# pipeline2 = make_pipeline(OrdinalEncoder(),\n",
        "#                          rf_random)\n",
        "\n",
        "# pipeline2.fit(Combined_X, Combined_y)\n",
        "# y_pred = pipeline2.predict(test)\n",
        "# pd.DataFrame(data={\"id\":test_id_col,\"status_group\":y_pred}).to_csv(\"water_pred.csv\", index=False)\n",
        "# pd.read_csv('water_pred.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPC3PUJbALe_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ycx1ihSBa2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "l4y_GcZ380Zc",
        "colab": {}
      },
      "source": [
        "#output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x0T62jPujpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import lightgbm\n",
        "import xgboost as xgb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kP_CXKn2Bzm9",
        "colab": {}
      },
      "source": [
        "# ohe = OneHotEncoder(use_cat_names=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GJSKqhJlBy78",
        "colab": {}
      },
      "source": [
        "# encoded_X = ohe.fit_transform(X)\n",
        "# encoded_y = y.replace({'functional': 3, 'non functional': 2, 'functional needs repair': 1})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gpMYYTOtByni",
        "colab": {}
      },
      "source": [
        "# XG_train, XG_validate, yG_train, yG_validate = train_test_split(encoded_X,encoded_y, test_size=.2, random_state=99)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hN4-xAfUBxCE",
        "colab": {}
      },
      "source": [
        "# encoded_y.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L9hC1yuTBuOg",
        "colab": {}
      },
      "source": [
        "# model1 = xgb.XGBClassifier()\n",
        "# model2 = xgb.XGBClassifier(n_estimators=200, max_depth=12, learning_rate=0.3, subsample=0.5)\n",
        "\n",
        "# train_model1 = model1.fit(XG_train, yG_train)\n",
        "# train_model2 = model2.fit(XG_train, yG_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MOJ7JnMIBpGw",
        "colab": {}
      },
      "source": [
        "#{3:'functional': 2:'non functional', 1: 'functional needs repair'}\n",
        "\n",
        "\n",
        "# pred1 = train_model1.predict(XG_validate)\n",
        "# pred2 = train_model2.predict(XG_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6fvMLByoBnW2",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i3QVwTyGNyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# accuracy_score(yG_validate, pred1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s4QwfUB5BmCk",
        "colab": {}
      },
      "source": [
        "# accuracy_score(yG_validate, pred2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gYng-MiJoxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ohe2 = OneHotEncoder(use_cat_names=True, handle_unknown=\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ExOvUWiS0vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "XG_encoder = ohe2.fit(Combined_X)\n",
        "encoded_train_X = XG_encoder.transform(Combined_X)\n",
        "encoded_Combo_y = Combined_y.replace({'functional': 3, 'non functional': 2, 'functional needs repair': 1})\n",
        "encoded_test = XG_encoder.transform(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWmbRbVXHRBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# model_with_params = xgb.XGBClassifier(n_estimators=200, max_depth=12, learning_rate=0.3, subsample=0.6)\n",
        "\n",
        "# trained_with_params = model_with_params.fit(encoded_train_X, encoded_Combo_y)\n",
        "\n",
        "# XGboost_pred = trained_with_params.predict(encoded_test)\n",
        "\n",
        "# XGboost_pred = pd.Series(XGboost_pred).replace({3: 'functional', 2:'non functional', 1:'functional needs repair'})\n",
        "# pd.DataFrame(data={\"id\":test_id_col,\"status_group\":XGboost_pred}).to_csv(\"water_pred_xgb.csv\", index=False)\n",
        "# pd.read_csv('water_pred_xgb.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOQ3JmN1NG_Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROpwSZPdWYDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = xgb.XGBClassifier()\n",
        "parameters = {\n",
        "     \"eta\"    : [0.05, 0.10, 0.15, 0.20, 0.25, 0.30 ] ,\n",
        "     \"max_depth\"        : [ 3, 4, 5, 6, 8, 10, 12, 15],\n",
        "     \"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
        "     \"gamma\"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],\n",
        "     \"colsample_bytree\" : [ 0.3, 0.4, 0.5 , 0.7 ]\n",
        "     }\n",
        "\n",
        "grid = GridSearchCV(clf,\n",
        "                    parameters, n_jobs=2,\n",
        "                    scoring=\"neg_log_loss\",\n",
        "                    cv=3)\n",
        "\n",
        "grid.fit(encoded_train_X, encoded_Combo_y)\n",
        "XGboost_predGV = trained_with_params.predict(encoded_test)\n",
        "XGboost_predGV = pd.Series(XGboost_predGV).replace({3: 'functional', 2:'non functional', 1:'functional needs repair'})\n",
        "\n",
        "pd.DataFrame(data={\"id\":test_id_col,\"status_group\":XGboost_predGV}).to_csv(\"water_pred_xgbGV.csv\", index=False)\n",
        "\n",
        "pd.read_csv('water_pred_xgbGV.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}