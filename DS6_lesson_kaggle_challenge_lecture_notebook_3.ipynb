{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DS6_lesson_kaggle_challenge_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Scott-Huston/DS-Unit-2-Kaggle-Challenge/blob/master/DS6_lesson_kaggle_challenge_lecture_notebook_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-hTictxWYih7"
      },
      "source": [
        "Lambda School Data Science, Unit 2: Predictive Modeling\n",
        "\n",
        "# Kaggle Challenge, Module 3\n",
        "\n",
        "\n",
        "#### Objectives\n",
        "- Get **permutation importances** for model interpretation and feature selection\n",
        "- Use xgboost for **gradient boosting**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LoxNYFBXYih9"
      },
      "source": [
        "### Default Feature Importances are fast, but Permutation Importances may be more accurate\n",
        "\n",
        "- Permutation Importances\n",
        "  - [Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)\n",
        "  - [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "- (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "### Try Tree Ensembles when you do machine learning with labeled, tabular data\n",
        "- \"Tree Ensembles\" means Random Forest or **Gradient Boosting** models. \n",
        "- [Tree Ensembles often have the best predictive accuracy](https://arxiv.org/abs/1708.05070) with labeled, tabular data.\n",
        "- Why? Because trees can fit non-linear, non-[monotonic](https://en.wikipedia.org/wiki/Monotonic_function) relationships, and [interactions](https://christophm.github.io/interpretable-ml-book/interaction.html) between features.\n",
        "- A single decision tree, grown to unlimited depth, will [overfit](http://www.r2d3.us/visual-intro-to-machine-learning-part-1/). We solve this problem by ensembling trees, with bagging (Random Forest) or **[boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw)** (Gradient Boosting).\n",
        "- Random Forest's advantage: may be less sensitive to hyperparameters. **Gradient Boosting's advantage:** may get better predictive accuracy.\n",
        "\n",
        "#### Python libraries for Gradient Boosting\n",
        "- [scikit-learn Gradient Tree Boosting](https://scikit-learn.org/stable/modules/ensemble.html#gradient-boosting) — slower than other libraries, but [the new version may be better](https://twitter.com/amuellerml/status/1129443826945396737)\n",
        "  - Anaconda: already installed\n",
        "  - Google Colab: already installed\n",
        "- [xgboost](https://xgboost.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://xiaoxiaowang87.github.io/monotonicity_constraint/)\n",
        "  - Anaconda, Mac/Linux: `conda install -c conda-forge xgboost`\n",
        "  - Windows: `conda install -c anaconda py-xgboost`\n",
        "  - Google Colab: already installed\n",
        "- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) — can accept missing values and enforce [monotonic constraints](https://blog.datadive.net/monotonicity-constraints-in-machine-learning/)\n",
        "  - Anaconda: `conda install -c conda-forge lightgbm`\n",
        "  - Google Colab: already installed\n",
        "- [CatBoost](https://catboost.ai/) — can accept missing values and use [categorical features](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html) without preprocessing\n",
        "  - Anaconda: `conda install -c conda-forge catboost`\n",
        "  - Google Colab: `pip install catboost`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMejJg0w8v76",
        "colab_type": "text"
      },
      "source": [
        "### Setup\n",
        "\n",
        "#### If you're using [Anaconda](https://www.anaconda.com/distribution/) locally\n",
        "\n",
        "Install required Python packages, if you haven't already:\n",
        "\n",
        "[category_encoders](http://contrib.scikit-learn.org/categorical-encoding/), version >= 2.0  \n",
        "`conda install -c conda-forge category_encoders`\n",
        "\n",
        "[eli5](https://github.com/TeamHG-Memex/eli5), version >= 0.9  \n",
        "`conda install -c conda-forge eli5`\n",
        "\n",
        "[xgboost](https://xgboost.readthedocs.io/en/latest/)  \n",
        "`conda install -c conda-forge xgboost` \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BFQMky3CYih-",
        "colab": {}
      },
      "source": [
        "# If you're in Colab...\n",
        "import os, sys\n",
        "in_colab = 'google.colab' in sys.modules\n",
        "\n",
        "if in_colab:\n",
        "    # Install required python packages:\n",
        "    # category_encoders, version >= 2.0\n",
        "    # eli5, version >= 0.9\n",
        "    # pandas-profiling, version >= 2.0\n",
        "    # plotly, version >= 4.0\n",
        "    !pip install --upgrade category_encoders eli5 pandas-profiling plotly\n",
        "    \n",
        "    # Pull files from Github repo\n",
        "    os.chdir('/content')\n",
        "    !git init .\n",
        "    !git remote add origin https://github.com/LambdaSchool/DS-Unit-2-Kaggle-Challenge.git\n",
        "    !git pull origin master\n",
        "    \n",
        "    # Change into directory for module\n",
        "    os.chdir('module3')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-TExplb_Slf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Merge train_features.csv & train_labels.csv\n",
        "train = pd.merge(pd.read_csv('../data/tanzania/train_features.csv'), \n",
        "                 pd.read_csv('../data/tanzania/train_labels.csv'))\n",
        "\n",
        "# Read test_features.csv & sample_submission.csv\n",
        "test = pd.read_csv('../data/tanzania/test_features.csv')\n",
        "sample_submission = pd.read_csv('../data/tanzania/sample_submission.csv')\n",
        "\n",
        "\n",
        "# Split train into train & val\n",
        "train, val = train_test_split(train, train_size=0.80, test_size=0.20, \n",
        "                              stratify=train['status_group'], random_state=42)\n",
        "\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "    \n",
        "    # About 3% of the time, latitude has small values near zero,\n",
        "    # outside Tanzania, so we'll treat these values like zero.\n",
        "    X['latitude'] = X['latitude'].replace(-2e-08, 0)\n",
        "    \n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    # Also create a \"missing indicator\" column, because the fact that\n",
        "    # values are missing may be a predictive signal.\n",
        "    cols_with_zeros = ['longitude', 'latitude', 'construction_year', \n",
        "                       'gps_height', 'population']\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "        X[col+'_MISSING'] = X[col].isnull()\n",
        "            \n",
        "    # Drop duplicate columns\n",
        "    duplicates = ['quantity_group', 'payment_type']\n",
        "    X = X.drop(columns=duplicates)\n",
        "    \n",
        "    # Drop recorded_by (never varies) and id (always varies, random)\n",
        "    unusable_variance = ['recorded_by', 'id']\n",
        "    X = X.drop(columns=unusable_variance)\n",
        "    \n",
        "    # Convert date_recorded to datetime\n",
        "    X['date_recorded'] = pd.to_datetime(X['date_recorded'], infer_datetime_format=True)\n",
        "    \n",
        "    # Extract components from date_recorded, then drop the original column\n",
        "    X['year_recorded'] = X['date_recorded'].dt.year\n",
        "    X['month_recorded'] = X['date_recorded'].dt.month\n",
        "    X['day_recorded'] = X['date_recorded'].dt.day\n",
        "    X = X.drop(columns='date_recorded')\n",
        "    \n",
        "    # Engineer feature: how many years from construction_year to date_recorded\n",
        "    X['years'] = X['year_recorded'] - X['construction_year']\n",
        "    X['years_MISSING'] = X['years'].isnull()\n",
        "    \n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhg8PQKt_jzP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'status_group'\n",
        "X_train = train.drop(columns=target)\n",
        "y_train = train[target]\n",
        "X_val = val.drop(columns=target)\n",
        "y_val = val[target]\n",
        "X_test = test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8lB4z5l_eml",
        "colab_type": "code",
        "outputId": "7be90efa-5717-4159-862f-f3dd7a71c134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8135521885521886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7HOayKBOYiit"
      },
      "source": [
        "# 3 types of feature importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4bRhsxENYiiu"
      },
      "source": [
        "## 1. (Default) Feature Importances\n",
        "\n",
        "Fastest, good for first estimates, but be aware:\n",
        "\n",
        "\n",
        "\n",
        ">**When the dataset has two (or more) correlated features, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others.** But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable. — [Selecting good features – Part III: random forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/) \n",
        "\n",
        "\n",
        " \n",
        " > **The scikit-learn Random Forest feature importance ... tends to inflate the importance of continuous or high-cardinality categorical variables.** ... Breiman and Cutler, the inventors of Random Forests, indicate that this method of “adding up the gini decreases for each individual variable over all trees in the forest gives a **fast** variable importance that is often very consistent with the permutation importance measure.” —  [Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BNVm6f7mYiiu",
        "outputId": "f1b51771-ffd7-4031-f831-d87a8ab42f68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 20\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAJOCAYAAACzyR8VAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XuYXlV99//3R0AhhoOCpY6PGkUt\nAkKEgXoABaq0nrGiqFRFvSQeqfrDlp+ncTw8RWlLpR6jRTwgUsTTg1W0AhIRhElCAihKH8DWjqJY\nCWAICnyfP+4VvRknmZmQ5J7Zeb+uK1f2vfbaa333HS/5ZGXtPakqJEmSpC65x6ALkCRJkjY2Q64k\nSZI6x5ArSZKkzjHkSpIkqXMMuZIkSeocQ64kSZI6x5ArSdrokjwgyXeT3JzkPYOuR9KWx5ArSbNY\nklv6ft2Z5Na+z0dt5LlOTvJ/WzD9fpIXTDi/f5LLkqxOckmSvdYz3KuB66pq+6p6y92s63NJ3np3\nxpC05THkStIsVlXz1/4C/hN4Rl/baRt5upuApwA7AscAH0myH0CS7YAvA4uB+wBnAl9MsvU6xnow\n8P2NXN8GWU+NkjrMkCtJc1iS7ZJ8MMlPk/wkyYlJtmnn/iLJfyQZTfI/Sa5N8tx1jVVVb62qH1XV\nnVX1HeB7wGPa6ScDa6rqQ1V1G/APwPbAgZPUdDpwJPC2tuJ8UJKtkrwtyTVJbkhyWpKdWv+tk5yV\n5PokNyY5L8mftHPHAs/pG+vMJNsmqST/q2/O36329t3325JcD3y4tT87yco2x5Ike/Rd/7b2Hd6U\n5AdJDtrQPxNJs4MhV5LmtlFgb+BRwH7AwcDf9J1fANwT+GPgFcAnkzxkqkGTzAf2Ba5sTXsCK9ae\nr6o7gSta+11U1QuAs4B3tRXnJcBxwGH0QvH/An4LnNR32ZeB3VqdVwGfbGOdPGGsdYb0CRYA2wAP\nBI5N8hjgQ8BLgZ2BTwNfagF7n9a+kN4q9tOAn0xzHkmzlCFXkua2o4CRqrqhqq4H3g28qO/87cBo\nVf2mqv4d+HfgiPUNmCTAx4HvVNX5rXk+sGpC11X0VnOn45XA8VU1XlVr6IXzI5Okqm6vqk9V1S19\n5w5Isu00x57MbfSC8W+q6lZgEfCBqlpaVXdU1WLgXvT+YnA7sB2wB7BVVV1TVdfejbklzQKGXEma\no1oY/WPgx33NPwYe0Pf5Fy049p8fmmLok+ntqf2rvrZbgB0m9NsBuHmadT4Q+Le2VeBGYDm9/wbt\n3FZT/6FtZbiJ3kpu6K24bqifVdVv+z4/GHjz2vlbDfcDHlBVVwLHA+8Bft62Uux6N+aWNAsYciVp\njqqqAn5GL8Ct9SDgv/s+7zJhRfRBwPi6xkzyXnpbCp5SVbf0nboS2Kev3z2Avfj9doap6vxv4NCq\n2qnv17ZVdQO9rQJPBg6ht11g97XTrB1iwpC/obfdYV5f2x9PnHbC5/8C3j5h/nlV9YVW4yer6nHA\nQ4Ft6a2IS5rDDLmSNLedDowk2TnJHwFvAT7Td34beg9t3TPJofTC5FmTDZRkFHgmcFhV3Tjh9DeB\n7ZK8Msm9gDcAvwa+M806PwKckOSBba4/SvKMdm57YA3wS+De/GHAvJ5e+AR+tx/4cuCo9kDbM4HH\nTjH/YuB1SYbTMz/JM5PMS7JHkie2+7q1/bpzmvclaZYy5ErS3PZ2eq/quhK4DLgQeF/f+evo7Tn9\nGXAK8NKqumbiIC3gvZ1emLy27128bwRo+1qfRW9v7Y3A84HDq+r2adb5Pnr7gc9NcjPwXXoPtgH8\nC/CLVuPl/GFwXgzs37YZfK61vZbeGxx+BRwOnL2+yavqQuBY4KOt/h8BL6S34rsdvbdF3AD8lN7+\n47dN874kzVLp/SuSJKlrkvwFvYetHjboWiRpc3MlV5IkSZ1jyJUkSVLnuF1BkiRJneNKriRJkjpn\n60EXoMHbZZddasGCBYMuQ5IkaUpLly69oaruN1U/Q65YsGABY2Njgy5DkiRpSkl+PHUvtytIkiSp\ngwy5kiRJ6hxDriRJkjrHkCtJkqTOMeRKkiSpc3y7ghgfH2d0dHTQZUiSpDlsZGRk0CXchSu5kiRJ\n6hxDriRJkjrHkCtJkqTOMeTOEUlen2Re3+d/S7JT+/XqQdYmSZI02xhy547XA78LuVX11Kq6EdgJ\nMORKkiT1MeRuJEnekuRHSb6T5PQkxyU5P8lwO79Lkuva8YIkS5Isa78e19oPbtd8PslVSU5Lz7HA\nEHBekvNa3+uS7AKcAOyW5LIkJyb5VJLD++o6LcmzNvPXIUmSNFC+QmwjSLIf8HxgIb3vdBmwdD2X\n/Bx4clWtSfJw4HRguJ17NLAnMA5cCDy+qk5O8kbgkKq6YcJYxwN7VdXCVssTgTcAX0qyI/A44CWT\n1HwMcAzAjjvuOPObliRJmsVcyd04DgK+WFWrq+om4CtT9N8G+FiSy4EzgT36zl1SVT+pqjuBy4AF\nMymkqr4NPDzJ/YAXAGdV1e2T9FtcVcNVNTxv3rw/GEeSJGkucyV307qd3/9FYtu+9jcA1wP7tPNr\n+s7d1nd8Bxv2Z/Qp4K/orS6/dAOulyRJmtNcyd04LgAOT7Jdku2BZ7T264D92vERff13BH7aVmtf\nBGw1jTluBrafZvup9B5Uo6q+P42xJUmSOsWQuxFU1TLgDGAF8DXg0nbq74FXJVkO7NJ3yYeAlyRZ\nAewO/Hoa0ywGvr72wbO+uX8JXJjkiiQntrbrgR8An9jwu5IkSZq7UlWDrqFzkrwDuKWq/n5A888D\nLgf2rapVU/UfGhqqRYsWbfrCJElSZ42MjGyWeZIsrarhqfq5ktsxSZ5EbxX3n6cTcCVJkrrIlVwx\nPDxcY2Njgy5DkiRpSq7kSpIkaYtlyJUkSVLnGHIlSZLUOYZcSZIkdY4hV5IkSZ1jyJUkSVLnGHIl\nSZLUOYZcSZIkdY4hV5IkSZ1jyJUkSVLnGHIlSZLUOYZcSZIkdc7Wgy5Agzc+Ps7o6Oigy5AkSQM0\nMjIy6BI2KldyJUmS1DmGXEmSJHWOIVeSJEmdY8idoSS3bIIxn5nk+HZ8eJI9NmCM85MMb+zaJEmS\n5iJD7ixQVV+pqhPax8OBGYdcSZIk/Z4hdwOl58QkVyS5PMmRrf3gtqr6+SRXJTktSdq5p7a2pUlO\nTnJ2az86yQeSPA54JnBiksuS7Na/QptklyTXtePtknwuyQ+SfBHYrq+2w5JclGRZkjOTzN+8344k\nSdJg+QqxDfeXwEJgH2AX4NIkF7Rzjwb2BMaBC4HHJxkDPgo8oaquTXL6xAGr6rtJvgKcXVWfB2j5\neDKvAlZX1SOT7A0sa/13Ad4KPKmqfp3kb4E3Au/svzjJMcAxADvuuOMGfgWSJEmzkyu5G+5A4PSq\nuqOqrge+Dezfzl1SVT+pqjuBy4AFwO7ANVV1bevzByF3hp4AfAagqlYCK1v7Y+htd7gwyWXAS4AH\nT7y4qhZX1XBVDc+bN+9uliJJkjS7uJK7adzWd3wHd+97vp3f/2Vk22n0D/DNqnrB3ZhTkiRpTnMl\nd8MtAY5MslWS+9FbWb1kPf1/CDw0yYL2+ch19LsZ2L7v83XAfu34iL72C4AXAiTZC9i7tV9Mb3vE\nw9q5eyd5xDTuR5IkqTMMuRvui/S2CKwAzgX+pqp+tq7OVXUr8Grg60mW0guzqybp+jngTUmWJ9kN\n+HvgVUmW09v7u9aHgflJfkBvv+3SNs8vgKOB05OsBC6it1VCkiRpi5GqGnQNW4wk86vqlva2hQ8C\nV1fVSYOua2hoqBYtWjToMiRJ0gCNjIwMuoRpSbK0qqb82QCu5G5er2gPg10J7EjvbQuSJEnayFzJ\nFcPDwzU2NjboMiRJkqbkSq4kSZK2WIZcSZIkdY4hV5IkSZ1jyJUkSVLnGHIlSZLUOYZcSZIkdY4h\nV5IkSZ1jyJUkSVLnGHIlSZLUOYZcSZIkdY4hV5IkSZ1jyJUkSVLnbD3oAjR44+PjjI6ODroMSZK0\nCYyMjAy6hIFwJVeSJEmdY8iVJElS5xhyJUmS1DmG3E0gyS1TnN8pyav7Pg8l+Xw7XpjkqRsw5zuS\nHDfzaiVJkrrHkDsYOwG/C7lVNV5VR7SPC4EZh1xJkiT9niF3E0oyP8m3kixLcnmSZ7VTJwC7Jbks\nyYlJFiS5Isk9gXcCR7ZzR05coW39FrTjtyT5UZLvAH/S12e3JF9PsjTJkiS7b7abliRJmgV8hdim\ntQZ4dlXdlGQX4OIkXwGOB/aqqoUAa0NrVf0myduB4ap6bTv3jskGTrIf8Hx6K79bA8uApe30YuCV\nVXV1kj8FPgQcOuH6Y4BjAHbccceNdb+SJEmzgiF30wrwv5M8AbgTeACw60Ya+yDgi1W1GqCFZ5LM\nBx4HnJlkbd97Tby4qhbTC8MMDQ3VRqpJkiRpVjDkblpHAfcD9quq3ya5Dth2hmPczl23lUx1/T2A\nG9euEkuSJG2J3JO7ae0I/LwF3EOAB7f2m4Ht13HNxHPXAfsCJNkXeEhrvwA4PMl2SbYHngFQVTcB\n1yZ5brsmSfbZeLckSZI0+xlyN63TgOEklwMvBq4CqKpfAhe2h8hOnHDNecAeax88A84C7pvkSuC1\nwI/aGMuAM4AVwNeAS/vGOAp4eZIVwJXAs5AkSdqCuF1hE6iq+e33G4DHrqPPCyc07dXa/wfYf8K5\nw9YxxnuA90zSfi3wFzOrWpIkqTtcyZUkSVLnpMoH67d0w8PDNTY2NugyJEmSppRkaVUNT9XPlVxJ\nkiR1jiFXkiRJnWPIlSRJUucYciVJktQ5hlxJkiR1jiFXkiRJnWPIlSRJUucYciVJktQ5hlxJkiR1\njiFXkiRJnWPIlSRJUucYciVJktQ5hlxJkiR1ztaDLkCDNz4+zujo6KDLkCTN0MjIyKBLkGYtV3Il\nSZLUOYZcSZIkdY4hdxNIcnSSoUHXIUmStKUy5G4aRwOGXEmSpAEx5K5HkjclObYdn5Tk3HZ8aJLT\nktzS2q9M8q0k90tyBDAMnJbksiTbrWPs65KMJlmW5PIku7f2A5JclGR5ku8m+ZPWfnSSLyX5Zrv2\ntUne2PpdnOS+rd9uSb6eZGmSJWvHlSRJ2pIYctdvCXBQOx4G5ifZprVdANwbGKuqPYFvAyNV9Xlg\nDDiqqhZW1a3rGf+GqtoX+DBwXGu7Cjioqh4NvB3433399wL+EtgfeA+wuvW7CHhx67MYeF1V7dfG\n/NBkEyc5JslYkrHVq1dP8+uQJEmaG3yF2PotBfZLsgNwG7CMXtg9CDgWuBM4o/X9DPCFGY6/tv9S\neuEVYEfgk0keDhSwTV//86rqZuDmJKuA/9PaLwf2TjIfeBxwZpK119xrsomrajG9QMzQ0FDNsG5J\nkqRZzZC7HlX12yTX0ttj+11gJXAI8DDgB5NdMsMpbmu/38Hv/yzeRS/MPjvJAuD8SfpDL2Df1ne8\nNb2V+RurauEM65AkSeoUtytMbQm9f/a/oB2/ElheVUXv+zui9Xsh8J12fDOw/QbOtyPw3+346Jlc\nWFU3AdcmeS5AevbZwDokSZLmLEPu1JYA9wcuqqrrgTWtDeDXwAFJrgAOBd7Z2k8FPrK+B8/W433A\n3yVZzoattB8FvDzJCuBK4FkbMIYkSdKclt6CpDZEkluqav6g67i7hoaGatGiRYMuQ5I0Q/5YX22J\nkiytquGp+rmSK0mSpM5xJXcTS/JF4CETmv+2qs4ZRD2TGR4errGxsUGXIUmSNKXpruT6doVNrKqe\nPegaJEmStjRuV5AkSVLnGHIlSZLUOYZcSZIkdY4hV5IkSZ1jyJUkSVLnGHIlSZLUOYZcSZIkdY4h\nV5IkSZ1jyJUkSVLnGHIlSZLUOYZcSZIkdY4hV5IkSZ2z9aAL0OCNj48zOjo66DIkqRNGRkYGXYIk\nXMmVJElSBxlyJUmS1DmGXEmSJHWOIXcjSvKOJMfNoP9wkpPb8dFJPrAh40iSJOmufPBsgKpqDBgb\ndB2SJEld40ruFJLcO8lXk6xIckWSI5Ncl2SXdn44yfl9l+yT5KIkVyd5RevzuSRP6xvz1CRHJDk4\nydlTzP+KJJe2+c9KMq+175bk4iSXJ3l3klv6rnlTu2ZlEl+bIEmStjiG3Kn9BTBeVftU1V7A16fo\nvzdwKPBY4O1JhoAzgOcBJLkn8GfAV6c5/xeqav+q2gf4AfDy1v5+4P1V9SjgJ2s7JzkMeDhwALAQ\n2C/JEyYOmuSYJGNJxlavXj3NUiRJkuYGQ+7ULgeenOS9SQ6qqlVT9P9yVd1aVTcA59ELm18DDkly\nL+ApwAVVdes0598ryZIklwNHAXu29scCZ7bjz/b1P6z9Wg4sA3anF3rvoqoWV9VwVQ3PmzdvmqVI\nkiTNDe7JnUJV/SjJvsBTgXcn+RZwO7//C8K2Ey/5wyFqTdvS8OfAkcDnZlDCqcDhVbUiydHAwVP0\nD/B3VfXRGcwhSZLUKa7kTqFtN1hdVZ8BTgT2Ba4D9mtdnjPhkmcl2TbJzvQC6aWt/QzgpcBBTL3l\nod/2wE+TbENvJXeti/vmfn5f+znAy5LMb/U/IMkfzWA+SZKkOc+V3Kk9CjgxyZ3Ab4FXAdsB/5Lk\nXcD5E/qvpLdNYRfgXVU13tq/AXya3naG38xg/rcB3wN+0X7fvrW/HvhMkrfQC82rAKrqG0keCVyU\nBOAW4K+An89gTkmSpDktVRP/dV1zQXvLwq1VVUmeD7ygqp61IWMNDQ3VokWLNm6BkrSFGhkZGXQJ\nUqclWVpVw1P1cyV37toP+EB6y7U3Ai/b0IGGhob8P2VJktQphtw5qqqWAPsMug5JkqTZyAfPJEmS\n1DmGXEmSJHWOIVeSJEmdY8iVJElS5xhyJUmS1DmGXEmSJHWOIVeSJEmdY8iVJElS5xhyJUmS1DmG\nXEmSJHWOIVeSJEmdY8iVJElS52w96AI0eOPj44yOjg66DEkdNjIyMugSJG1hXMmVJElS5xhyJUmS\n1DmGXEmSJHWOIVeSJEmdY8jdTJIcnOTsGV7zziRPmqLPO5IcN0n7TklePdM6JUmSusCQO4tV1dur\n6t838PKdAEOuJEnaIhlyJ5HkbUl+mOQ7SU5PclyS85O8P8llSa5IckDr+8TWdlmS5Um2X8/Q85N8\nPslVSU5LkjbGfkm+nWRpknOS3L+1n5rkiHb81Hbd0iQnT1gV3qPVd02SY1vbCcBura4TJ7nHY5KM\nJRlbvXr1xvjaJEmSZg3fkztBkv2B5wD7ANsAy4Cl7fS8qlqY5AnAKcBewHHAa6rqwiTzgTXrGf7R\nwJ7AOHAh8Pgk3wP+GXhWVf0iyZHAe4CX9dW0LfBR4AlVdW2S0yeMuztwCLA98MMkHwaOB/aqqoWT\nFVJVi4HFAENDQzWNr0aSJGnOMOT+occDX66qNcCaJP+n79zpAFV1QZIdkuxEL6z+Y5LTgC9U1U/W\nM/Yla88nuQxYANxILyx/sy3sbgX8dMJ1uwPXVNW1fXUc03f+q1V1G3Bbkp8Du870piVJkrrEkDsz\nE1c8q6pOSPJV4KnAhUn+vKquWsf1t/Ud30Hv+w9wZVU99m7UNdm4kiRJWyz35P6hC4FnJNm2bT94\net+5IwGSHAisqqpVSXarqsur6r3ApfRWXWfih8D9kjy2jb1Nkj0n6fPQJAv665jCzfS2L0iSJG1x\nXPGboKouTfIVYCVwPXA5sKqdXpNkOb29umv3zL4+ySHAncCVwNdmON9v2sNlJyfZkd6fyT+1sdb2\nubW9DuzrSX5NL0xPNe4vk1yY5Arga1X1ppnUJUmSNJelymeOJkoyv6puSTIPuIDe/td/BI6rqrEB\n1xTgg8DVVXXSxhh7eHi4xsYGcluSJEkzkmRpVQ1P1c/tCpNb3B4MWwacVVXLBl0Q8IpW05XAjvTe\ntiBJkqRJuF1hElX1wknaDp7OtUkeBXx6QvNtVfWnd7Omk4CNsnIrSZLUdYbcjayqLgcmfTetJEmS\nNg+3K0iSJKlzDLmSJEnqHEOuJEmSOseQK0mSpM4x5EqSJKlzDLmSJEnqHEOuJEmSOseQK0mSpM4x\n5EqSJKlzDLmSJEnqHH+srxgfH2d0dHTQZUiawsjIyKBLkKQ5w5VcSZIkdY4hV5IkSZ1jyJUkSVLn\nGHIlSZLUOVtUyE3yjiTHDbqODZXk4CRnz/Ca85MMb6qaJEmSZqMtKuRuKkk2yVsqkmy1KcaVJEnq\nus6H3CRvSfKjJN8B/qS1vSLJpUlWJDkrybwk2ye5Nsk2rc8O/Z8nGff8JP+UZAz46yT3a2Nd2n49\nvvWbn+QTSS5PsjLJc1r7C1rbFUne2zfuLUn+IckK4LFJ/iLJVUmWAX/Z1+/eSU5JckmS5Ume1dq3\nS/K5JD9I8kVgu3XUf0ySsSRjq1ev3gjftCRJ0uzR6ffkJtkPeD6wkN69LgOWAl+oqo+1Pu8GXl5V\n/5zkfOBpwJfadV+oqt+uZ4p7VtVwG+ezwElV9Z0kDwLOAR4JvA1YVVWPav3uk2QIeC+wH/Ar4BtJ\nDq+qLwH3Br5XVf9fkm2Bq4FDgf8Azuib+y3AuVX1siQ7AZck+XdgEbC6qh6ZZO92z3+gqhYDiwGG\nhoZqWl+oJEnSHNH1ldyDgC9W1eqqugn4SmvfK8mSJJcDRwF7tvaPAy9txy8FPjHF+P2h80nAB5Jc\n1ubZIcn81v7BtZ2q6lfA/sD5VfWLqrodOA14QutyB3BWO94duLaqrq6qAj7TN99hwPFtvvOBbYEH\ntXE+0+ZaCayc4h4kSZI6p9MruetxKnB4Va1IcjRwMEBVXZhkQZKDga2q6oopxvl13/E9gMdU1Zr+\nDklmWtuaqrpjGv0CPKeqfng355MkSeqcrq/kXgAc3vapbg88o7VvD/y07bc9asI1nwI+y9SruBN9\nA3jd2g9JFrbDbwKv6Wu/D3AJ8MQku7SHy14AfHuSMa8CFiTZrX1+Qd+5c4DXpaXaJI9u7RcAL2xt\newF7z/A+JEmS5rxOh9yqWkZvS8EK4GvApe3U24DvARfSC5L9TgPuA5w+w+mOBYbbw2XfB17Z2t8N\n3Kc9YLYCOKSqfgocD5zXaltaVV+epP41wDHAV9uDZz/vO/0uYBtgZZIr22eADwPzk/wAeCe9PciS\nJElblPS2emqtJEcAz6qqFw26ls1laGioFi1aNOgyJE1hZGRk0CVI0sAlWbr2wf/12VL35E4qyT8D\nTwGeOuhaNqehoSH/4ylJkjrFkNunql43sS3JB4HHT2h+f1XNdM+uJEmSNhND7hSq6jVT95IkSdJs\n0ukHzyRJkrRlMuRKkiSpcwy5kiRJ6hxDriRJkjrHkCtJkqTOMeRKkiSpcwy5kiRJ6hxDriRJkjrH\nkCtJkqTOMeRKkiSpc/yxvmJ8fJzR0dFBlyFpEiMjI4MuQZLmJFdyJUmS1DmGXEmSJHWOIVeSJEmd\nY8jtsCQLklwx6DokSZI2N0NuhyTZatA1SJIkzQa+XWGWSPIm4LaqOjnJScA+VXVokkOBlwM3AfsD\n2wGfr6qRdt11wBnAk4H3JbkaOKUN+43NfBuSJEmzgiu5s8cS4KB2PAzMT7JNa7sAeEtVDQN7A09M\nsnfftb+sqn2r6nPAJ4DXVdU+65ssyTFJxpKMrV69eqPfjCRJ0iAZcmePpcB+SXYAbgMuohd2D6IX\ngJ+XZBmwHNgT2KPv2jMAkuwE7FRVF7T2T69rsqpaXFXDVTU8b968jX4zkiRJg+R2hVmiqn6b5Frg\naOC7wErgEOBhwK3AccD+VfWrJKcC2/Zd/uvNW60kSdLs5kru7LKEXpi9oB2/kt7K7Q70guyqJLsC\nT5ns4qq6EbgxyYGt6ahNXrEkSdIsZMidXZYA9wcuqqrrgTXAkqpaQS/sXgV8FrhwPWO8FPhgksuA\nbOJ6JUmSZiW3K8wiVfUtYJu+z4/oOz56HdcsmPB5KdD/0NnfbNQiJUmS5gBXciVJktQ5qapB16AB\nGx4errGxsUGXIUmSNKUkS9trVdfLlVxJkiR1jiFXkiRJnWPIlSRJUucYciVJktQ5hlxJkiR1jiFX\nkiRJnWPIlSRJUucYciVJktQ5hlxJkiR1jiFXkiRJnWPIlSRJUucYciVJktQ5Ww+6AA3e+Pg4o6Oj\ngy5D6ryRkZFBlyBJWwxXciVJktQ5hlxJkiR1jiFXkiRJnWPIlSRJUud0PuQmeX2SeZthnmcmOX6K\nPguSvHCKPguTPHXjVidJkrRl6XzIBV4PzCjkJtlqppNU1Veq6oQpui0A1htygYWAIVeSJOlumDMh\nN8mbkhzbjk9Kcm47PjTJaUk+nGQsyZVJRtu5Y4Eh4Lwk57W2w5JclGRZkjOTzG/t1yV5b5JlwHOT\nnJ/k/UkuS3JFkgNav/sm+VKSlUkuTrJ3az86yQfa8alJTk7y3STXJDmi3cYJwEFtzDdMco/3BN4J\nHNn6HJnk6iT3a+fvkeQ/ktyvzfGRds8/SvL01merJCcmubTVuGgd3+cx7dqx1atXb4Q/IUmSpNlj\nzoRcYAlwUDseBuYn2aa1XQC8paqGgb2BJybZu6pOBsaBQ6rqkCS7AG8FnlRV+wJjwBv75vhlVe1b\nVZ9rn+dV1ULg1cAprW0UWF5VewNvBj61jnrvDxwIPJ1euAU4HlhSVQur6qSJF1TVb4C3A2e0PmcA\nnwGOal2eBKyoql+0zwuAA4CnAR9Jsi3wcmBVVe0P7A+8IslDJplrcVUNV9XwvHmbfDeHJEnSZjWX\nQu5SYL8kOwC3ARfRC7sH0QvAz2ursMuBPYE9JhnjMa39wiSXAS8BHtx3/owJ/U8HqKoLgB2S7EQv\nuH66tZ8L7NxqmuhLVXVnVX0f2HUD7netU4AXt+OXAZ/oO/evbY6rgWuA3YHDgBe3+/sesDPw8Lsx\nvyRJ0pwzZ37iWVX9Nsm1wNHAd4GVwCHAw4BbgeOA/avqV0lOBbadZJgA36yqF6xjml9PnHaKz+tz\n24R5N0hV/VeS65McSm/V9qj+05PUF+B1VXXOhs4pSZI0182llVzordgeR297whLglfRWbnegF1BX\nJdkVeErfNTcD27fji4HHJ3kYQJJ7J3nEeuY7svU7kN4WgFVt3qNa+8HADVV10zTr769lJn0+Tm/b\nwplVdUdf+3PbPt3dgIcCPwQzHSZAAAAgAElEQVTOAV7VtnKQ5BFJ7j3N+iRJkjphLobc+wMXVdX1\nwBp6e1xX0Au7VwGfBS7su2Yx8PUk57W9rEcDpydZSW/Lw+7rmW9NkuXAR+jtdQV4B71tEyvp7bV9\nyQzqXwnckWTFZA+eNecBe6x98Ky1fQWYz123KgD8J3AJ8DXglVW1hl4g/j6wLMkVwEeZQyv2kiRJ\nG0OqZvIv8FuOJOcDx1XV2CyoZRg4qaoO6ms7FTi7qj5/d8cfGhqqRYsmfQmDpI1oZGRk0CVI0pyX\nZGl72cB6ucI3y7UfMPEq7roXd6MaGhryP76SJKlTDLnrUFUHb8rxk/w58N4JzddW1bMn1HECv38F\nWX/70ZuuOkmSpLnNkDsg7e0HvgFBkiRpE5hrD55JkiRJUzLkSpIkqXMMuZIkSeocQ64kSZI6x5Ar\nSZKkzjHkSpIkqXMMuZIkSeocQ64kSZI6x5ArSZKkzjHkSpIkqXMMuZIkSeqcrQddgAZvfHyc0dHR\nQZchzXkjIyODLkGS1LiSK0mSpM4x5EqSJKlzDLmSJEnqHENuxyTZatA1SJIkDZoPng1QkncC/1NV\n/9Q+vwf4OXBP4HnAvYAvVtVIO/8l4IHAtsD7q2pxa78F+CjwJOA1SZ4OPBO4HfhGVR23WW9MkiRp\nwFzJHaxTgBcDJLkH8HzgZ8DDgQOAhcB+SZ7Q+r+sqvYDhoFjk+zc2u8NfK+q9gF+ADwb2LOq9gbe\nPdnESY5JMpZkbPXq1Zvm7iRJkgbEkDtAVXUd8MskjwYOA5YD+/cdLwN2pxd6oRdsVwAX01vRXdt+\nB3BWO14FrAH+JclfApMm2KpaXFXDVTU8b968jX1rkiRJA+V2hcH7OHA08Mf0Vnb/DPi7qvpof6ck\nB9PbjvDYqlqd5Hx62xYA1lTVHQBVdXuSA9o4RwCvBQ7d9LchSZI0exhyB++LwDuBbYAX0ttH+64k\np1XVLUkeAPwW2BH4VQu4uwOPmWywJPOBeVX1b0kuBK7ZLHchSZI0ixhyB6yqfpPkPODGthr7jSSP\nBC5KAnAL8FfA14FXJvkB8EN6WxYmsz3w5STbAgHeuKnvQZIkabYx5A5Ye+DsMcBz17ZV1fuB90/S\n/SmTjVFV8/uOf0rvoTVJkqQtlg+eDVCSPYD/AL5VVVcPuh5JkqSuSFUNugYN2PDwcI2NjQ26DEmS\npCklWVpVw1P1cyVXkiRJnWPIlSRJUucYciVJktQ5hlxJkiR1jiFXkiRJnWPIlSRJUucYciVJktQ5\nhlxJkiR1jiFXkiRJnWPIlSRJUucYciVJktQ5hlxJkiR1jiFXkiRJnbP1oAvQ4I2PjzM6OjroMqRZ\na2RkZNAlSJJmyJVcSZIkdY4hV5IkSZ1jyJUkSVLnGHIHJMmCJFdMo88L+z4PJzl501cnSZI0txly\nZ7cFwO9CblWNVdWxgytHkiRpbjDkrkNbRb0qyWlJfpDk80nmJfmzJMuTXJ7klCT3av2vS/K+1n5J\nkoe19lOTHNE37i3rmGtJkmXt1+PaqROAg5JcluQNSQ5Ocna75r5JvpRkZZKLk+zd2t/R6jo/yTVJ\nDMWSJGmLY8hdvz8BPlRVjwRuAt4InAocWVWPovcKtlf19V/V2j8A/NMM5vk58OSq2hc4Eli7JeF4\nYElVLayqkyZcMwosr6q9gTcDn+o7tzvw58ABwEiSbSZOmOSYJGNJxlavXj2DUiVJkmY/Q+76/VdV\nXdiOPwP8GXBtVf2otX0SeEJf/9P7fn/sDObZBvhYksuBM4E9pnHNgcCnAarqXGDnJDu0c1+tqtuq\n6gZ6AXrXiRdX1eKqGq6q4Xnz5s2gVEmSpNnPHwaxfjXh843AztPsv/b4dtpfJpLcA7jnJNe9Abge\n2Kf1XbMhxfa5re/4DvxzliRJWxhXctfvQUnWrsi+EBgDFqzdbwu8CPh2X/8j+36/qB1fB+zXjp9J\nb9V2oh2Bn1bVnW3MrVr7zcD266htCXAUQJKDgRuq6qZp3ZUkSVLHucK3fj8EXpPkFOD7wLHAxcCZ\nSbYGLgU+0tf/PklW0ltJfUFr+xjw5SQrgK8Dv55kng8BZyV58YQ+K4E72rWnAsv7rnkHcEqbbzXw\nkrt3q5IkSd2Rqon/Ii/ovfEAOLuq9ppm/+uA4bYPdk4ZGhqqRYsWDboMadYaGRkZdAmSpCbJ0qoa\nnqqfK7liaGjI/4hLkqROMeSuQ1VdB0xrFbf1X7DJipEkSdKM+OCZJEmSOseQK0mSpM4x5EqSJKlz\nDLmSJEnqHEOuJEmSOseQK0mSpM4x5EqSJKlzDLmSJEnqHEOuJEmSOseQK0mSpM4x5EqSJKlzDLmS\nJEnqnK0HXYAGb3x8nNHR0UGXIQ3UyMjIoEuQJG1EruRKkiSpcwy5kiRJ6hxDriRJkjrHkCtJkqTO\n6XzITfLmjTjWTkle3fd5KMnnN9b4kiRJ2jg6H3KBSUNuemZ6/zsBvwu5VTVeVUfcneI2hyRbDboG\nSZKkzWnWhNwkL06yMsmKJJ9OsiDJua3tW0ke1PqdmuTkJN9Nck2SI1r7/ZNckOSyJFckOSjJCcB2\nre20NuYPk3wKuAJ4YJJb+mo4Ismp7XjXJF9s9axI8jjgBGC3Nt6JbbwrWv9tk3wiyeVJlic5pLUf\nneQLSb6e5Ook71vPd/CyJP/U9/kVSU5qx3+V5JI290fXBtckH04yluTKJKN9116X5L1JlgHPnWSu\nY9p1Y6tXr97APzVJkqTZaVaE3CR7Am8FDq2qfYC/Bv4Z+GRV7Q2cBpzcd8n9gQOBp9MLngAvBM6p\nqoXAPsBlVXU8cGtVLayqo1q/hwMfqqo9q+rH6ynrZODbrZ59gSuB44H/28Z704T+rwGqqh4FvAD4\nZJJt27mFwJHAo4AjkzxwHXP+K/CMJNu0zy8FTknyyHb949v93QGsvZ+3VNUwsDfwxCR79433y6ra\nt6o+N3GiqlpcVcNVNTxv3rz1fA2SJElzz6wIucChwJlVdQNAVf0P8Fjgs+38p+mF2rW+VFV3VtX3\ngV1b26XAS5O8A3hUVd28jrl+XFUXT7OmD7d67qiqVVP0PxD4TOt/FfBj4BHt3LeqalVVrQG+Dzx4\nsgGq6hbgXODpSXYHtqmqy4E/A/YDLk1yWfv80HbZ89pq7XJgT2CPviHPmMZ9SpIkdc5c/Ylnt/Ud\nB6CqLkjyBOBpwKlJ/rGqPjXJtb+e8Ln6jrdl0+iv9w7W/71/nN4+4quAT7S20FvV/v/7OyZ5CHAc\nsH9V/apttei/h4n3KkmStEWYLSu55wLPTbIzQJL7At8Fnt/OHwUsWd8ASR4MXF9VH6MXFPdtp37b\n98//k7k+ySPbQ2jP7mv/FvCqNvZWSXYEbga2X8c4S1qdJHkE8CDgh+ureTJV9T3ggfS2X5zeV8sR\nSf6ojX/fdr870Auyq5LsCjxlpvNJkiR10awIuVV1JfAe4NtJVgD/CLyO3vaDlcCL6O3TXZ+DgRVJ\nltPbv/r+1r4YWJnktHVcdzxwNr1Q/dO+9r8GDklyObAU2KOqfglc2B5sO3HCOB8C7tH6nwEcXVW3\nsWH+Fbiwqn4F0LZlvBX4Rvs+vgncv6pW0NumcBW9rR0XbuB8kiRJnZKqmrqXNqskZwMnVdW3Nsd8\nQ0NDtWjRos0xlTRrjYyMDLoESdI0JFnaHrpffz9D7uyRZCfgEmBFVf3Ba782leHh4RobG9tc00mS\nJG2w6Ybcufrg2ZyX5HvAvSY0v6iqHjFZf0mSJE2fIXdAqupPB12DJElSV82KB88kSZKkjcmQK0mS\npM4x5EqSJKlzDLmSJEnqHEOuJEmSOseQK0mSpM4x5EqSJKlzDLmSJEnqHEOuJEmSOseQK0mSpM7x\nx/qK8fFxRkdHB12GtNmMjIwMugRJ0ibmSq4kSZI6x5ArSZKkzjHkSpIkqXMMuZtJkmOT/CDJaXdz\nnAVJrthYdUmSJHWRD55tPq8GnlRVP9mckybZuqpu35xzSpIkDZoruZtBko8ADwW+lmRVkuP6zl3R\nVmcXtJXejyW5Msk3kmzX+uyXZEWSFcBr+q7dKsmJSS5NsjLJotZ+cJIlSb4CfH/z3q0kSdLgGXI3\ng6p6JTAOHAKctJ6uDwc+WFV7AjcCz2ntnwBeV1X7TOj/cmBVVe0P7A+8IslD2rl9gb+uqkdMNlGS\nY5KMJRlbvXr1Bt2XJEnSbGXInV2urarL2vFSYEGSnYCdquqC1v7pvv6HAS9OchnwPWBnekEZ4JKq\nunZdE1XV4qoarqrhefPmbdy7kCRJGjD35G5+t3PXv1xs23d8W9/xHcB2U4wVeiu859ylMTkY+PXd\nqFGSJGlOcyV387uO3lYCkuwLPGR9navqRuDGJAe2pqP6Tp8DvCrJNm28RyS590avWJIkaY5xJXfz\nO4veFoMr6W0x+NE0rnkpcEqSAr7R1/5xYAGwLEmAXwCHb9xyJUmS5h5D7mZSVQv6Ph62jm579fX/\n+77jpUD/Q2d/09rvBN7cfvU7v/2SJEnaIrldQZIkSZ2Tqhp0DRqw4eHhGhsbG3QZkiRJU0qytKqG\np+rnSq4kSZI6x5ArSZKkzjHkSpIkqXMMuZIkSeocQ64kSZI6x5ArSZKkzjHkSpIkqXMMuZIkSeoc\nQ64kSZI6x5ArSZKkzjHkSpIkqXMMuZIkSeqcrQddgAZvfHyc0dHRQZchbRIjIyODLkGSNACu5EqS\nJKlzDLmSJEnqHEOuJEmSOseQK0mSpM7ZZCE3yeuTzNtU4/fN88wkx0/RZ0GSF07RZ2GSp27c6iRJ\nkjQIm3Il9/XAjEJukq1mOklVfaWqTpii2wJgvSEXWAjMqpC7Id+HJEmSphFyk7wpybHt+KQk57bj\nQ5OcluTDScaSXJlktJ07FhgCzktyXms7LMlFSZYlOTPJ/NZ+XZL3JlkGPDfJ+Unen+SyJFckOaD1\nu2+SLyVZmeTiJHu39qOTfKAdn5rk5CTfTXJNkiPabZwAHNTGfMMk93hP4J3Aka3PkUmuTnK/dv4e\nSf4jyf3aHB9p9/yjJE9vfbZKcmKSS1uNi9bznd4jyYeSXJXkm0n+bW2tk3wfC9v9rkzyxST3af3O\nTzLcjndJcl3f9/Hldv7qJJO+PynJMe0exlavXj3V/wwkSZLmlOms5C4BDmrHw8D8JNu0tguAt1TV\nMLA38MQke1fVycA4cEhVHZJkF+CtwJOqal9gDHhj3xy/rKp9q+pz7fO8qloIvBo4pbWNAsuram/g\nzcCn1lHv/YEDgafTC7cAxwNLqmphVZ008YKq+g3wduCM1ucM4DPAUa3Lk4AVVfWL9nkBcADwNOAj\nSbYFXg6sqqr9gf2BVyR5yDpq/Ms2xh7Ai4DHTjjf/318Cvjbdt+XA9N56ecBwHPo/Zk8d20YnnDP\ni6tquKqG583b5LtKJEmSNqvphNylwH5JdgBuAy6iF3YPoheAn9dWHZcDe9ILbhM9prVfmOQy4CXA\ng/vOnzGh/+kAVXUBsEOSnegF10+39nOBnVtNE32pqu6squ8Du07j/tblFODF7fhlwCf6zv1rm+Nq\n4Bpgd+Aw4MXt/r4H7Aw8fB1jHwic2cb4GXDehPNnACTZEdipqr7d2j8JPGEatX+zqn5ZVbcCX2jz\nSZIkbTGm/IlnVfXbJNcCRwPfBVYChwAPA24FjgP2r6pfJTkV2HaSYUIveL1gHdP8euK0U3xen9sm\nzLtBquq/klyf5FB6K6NH9Z+epL4Ar6uqczZ0zj4Tv4/J3M7v/5Iy8Tu/O9+fJEnSnDfdB8+W0Auz\nF7TjV9Jbud2BXiBblWRX4Cl919wMbN+OLwYen+RhAEnuneQR65nvyNbvQHpbAFa1eY9q7QcDN1TV\nTdOsv7+WmfT5OL1tC2dW1R197c9t+2p3Ax4K/BA4B3hV28pBkkckufc65roQeE4bY1fg4Mk6tfv+\nVZK120VeBKxd1b0O2K8dHzHh0ie3PczbAYe3+SRJkrYYMwm59wcuqqrrgTX09riuoBd2rwI+y13D\n1GLg60nOa3tZjwZOT7KS3paH3dcz35oky4GP0NvrCvAOetsmVtLba/uSadYOvdXnO5KsmOzBs+Y8\nYI+1D561tq8A87nrVgWA/wQuAb4GvLKq1tALxN8HliW5Avgo614pPwv4Sev/GWAZsGodfV8CnNju\neyG9B+QA/p5eqF4O7DLhmkvaHCuBs6pqbB1jS5IkdVKqZte/ZCc5HzhuNgSz9sDWSVV1UF/bqcDZ\nVfX5uzn2/Kq6JcnO9ELp49v+3LslydHAcFW9drrXDA0N1aJF63wZhDSnjYxM51lNSdJckWRpe+nB\nek25J3dLld4PmHgVd92LuzGd3R6ouyfwro0RcDfU0NCQQUCSJHXKrFvJ3dSS/Dnw3gnN11bVszfB\nXI+ivRGiz21V9acbe667Y3h4uMbGBr5wLkmSNCVXctehvf1gY7wBYTpzXU5vH60kSZI2o035Y30l\nSZKkgTDkSpIkqXMMuZIkSeocQ670/9q79yi7yjrN498HIkIIA4qXZSkapKGRQJOGAsQLRrDRdmyF\nNjOoqI30kuClbXXBqCNaxLFHEGd0uhEx2hK6ZRpGvCxEm2CjIqJAKpAbAVSEETvYIgqCkXD7zR9n\nZ/pYFqlKTlWd1K7vZ62zap+93/2e37urUnny5t3nSJKk1jHkSpIkqXUMuZIkSWodQ64kSZJax5Ar\nSZKk1jHkSpIkqXUMuZIkSWodQ64kSZJaZ1a/C1D/rV+/nsWLF/e7DM1wQ0ND/S5BktQizuRKkiSp\ndQy5kiRJah1D7gRK8r2tPO+YJPuNo93pSU5ptpcmWbg1rydJktR2htwJVFXP28pTjwHGDLm9SOL6\na0mSNGMYcidQkvubrwuSfDvJxUluTnJBkjTHzkiyLsnqJB9L8jzglcBZSVYm2SvJm5MsT7IqyReT\nzB7jdQ9OcmWSFUmWJXlas//bST6RZBj460keviRJ0jbD2b3J88fAPGA9cDXw/CQ3AccC+1ZVJdmt\nqu5JcglwaVVdDJDknqr6TLP9YeAvgb8b7UWSPK459qqquivJccDfACc2TXaoqsFRzjsJOAlg1113\nnbBBS5IkbQsMuZPnuqr6KUCSlcBc4BrgAeDvk1wKXPoY5+7fhNvdgDnAss28zh8C+wPfaCaLtwfu\n7Dp+0WgnVdUSYAnAwMBAjW9IkiRJ04Mhd/Js7Np+BJhVVQ8nORQ4ClgIvB04cpRzlwLHVNWqJCcA\nCzbzOgFurKrDH+P4b7awbkmSpGnPNblTKMkcYNeq+jrwLuDA5tB9wC5dTXcB7myWIhw/Rre3AE9O\ncnjzGo9LMm9iK5ckSZpeDLlTaxfg0iSrge8C7272XwicmuSGJHsBHwCupbOW9+bNdVhVD9KZFT4z\nySpgJbC17/IgSZLUCqlyOeZMNzAwUIsWLep3GZrh/FhfSdJ4JFkx2k31IzmTK0mSpNZxJlcMDg7W\n8PBwv8uQJEkakzO5kiRJmrEMuZIkSWodQ64kSZJax5ArSZKk1jHkSpIkqXUMuZIkSWodQ64kSZJa\nx5ArSZKk1jHkSpIkqXUMuZIkSWodQ64kSZJax5ArSZKk1jHkSpIkqXVm9bsA9d/69etZvHhxv8vQ\nDDY0NNTvEiRJLeNMriRJklrHkCtJkqTWMeRKkiSpdQy524gkxyTZb4w2JyQZGKPN0iQLJ7Y6SZKk\n6cWQu+04BthsyAVOADYbciVJkmTIBSDJV5KsSHJjkpOaffcnOavZ9y9JDk3y7SQ/TvLKps2OSc5L\nsibJDUle3Ow/IcnZXf1fmmRBV79/k2RVkmuSPDXJ84BXAmclWZlkr1FqXAgMAhc0bXZKckaSdUlW\nJ/lYV/MjknyvqXXUWd0kJyUZTjK8YcOGibmQkiRJ2whDbseJVXUwnRD5jiS7AzsD36yqecB9wIeB\nPwGOBT7UnPc2oKrqAOC1wPlJdhzjtXYGrqmqA4HvAG+uqu8BlwCnVtX8qrp15ElVdTEwDBxfVfOB\n2U0t86rqj5r6Nnka8ALgFcAZoxVRVUuqarCqBmfPnj1GyZIkSdOLIbfjHUlWAdcAewB7Aw8ClzXH\n1wBXVtVDzfbcZv8LgM8DVNXNwP8F9hnjtR4ELm22V3T1taXuBR4A/j7JnwPd07FfqapHq2od8NSt\n7F+SJGnamvEht1lG8BLg8GZ29QZgR+Chqqqm2aPARoCqepSxP0TjYX732nbP7nb3+8g4+hpVVT0M\nHApcTGfG9rKuwxu7trM1/UuSJE1nMz7kArsCv6qqDUn2BZ67BedeBRwPkGQf4JnALcDtwPwk2yXZ\ng04YHct9wC7jbZNkDrBrVX0deBdw4BbULUmS1GqG3M4M6KwkN9FZv3rNFpx7DrBdkjXARcAJVbUR\nuBq4DVgH/C1w/Tj6uhA4tbmB7fduPGssBc5NspJO2L00yWrgu8C7t6BuSZKkVsu//8+5ZqqBgYFa\ntGhRv8vQDDY0NNTvEiRJ00SSFVU1OGY7Q64GBwdreHi432VIkiSNabwhd6tuetLkSvJJ4Pkjdv+v\nqjqvH/VIkiRNN4bcbVBVva3fNUiSJE1n3ngmSZKk1jHkSpIkqXUMuZIkSWodQ64kSZJax5ArSZKk\n1jHkSpIkqXUMuZIkSWodQ64kSZJax5ArSZKk1jHkSpIkqXUMuZIkSWqdWf0uQP23fv16Fi9e3O8y\nNIMNDQ31uwRJUss4kytJkqTWMeRKkiSpdQy5kiRJah1DriRJklpnykJukt2SvHUC+1uQ5Hldz09O\n8sYJ7H9+kpdPVH9bWcPSJAv7WYMkSdJ0NJUzubsBo4bcJFvzLg8LgP8fcqvq3Kr6h60rbVTzgb6G\nXEmSJG2dnkNuktcnuS7JyiSfTvKsJD9M8qQk2yW5KsnRwBnAXk27s5qZ2KuSXAKsa/r6SpIVSW5M\nclLXa7wsyfVJViW5Islc4GTgXU1/L0xyepJTmvbzk1yTZHWSLyd5QrP/20nObOr9QZIXPsaYdgA+\nBBzX9H9cM6YnN8e3S/KjJE9uZlvPTTLc9PmKps32zTiXN3UsGuM6vifJmmaMZ4xy/INNX2uTLEmS\nZv87kqxrXuPCZt+LmrpXJrkhyS6j9HdSU/Pwhg0bNvs9liRJmm56ep/cJM8BjgOeX1UPJTkHeBFw\nJvAp4DpgXVVdnuQHwP5VNb85dwFwULPvtqbLE6vql0l2ApYn+SKdIP4Z4Iiqui3JE5s25wL3V9XH\nmv6O6irtH4C/qqork3wIGALeuWnMVXVosxRhCHjJyHFV1YNJPggMVtXbm/73BY4HPtGcs6qq7mqy\n5lzgUGAv4FtJ/gB4I3BvVR2S5PHA1Uku7xpr93X8U+BVwGFVtSHJE0e53GdX1Yea9v8IvAL4KvBe\nYM+q2phkt6btKcDbqurqJHOAB0YZ4xJgCcDAwECN8nqSJEnTVq8zuUcBB9MJpCub58+uqs8C/4HO\nbOspmzn/uhGh7x1JVgHXAHsAewPPBb6zqV1V/XJzBSXZFditqq5sdp0PHNHV5EvN1xV0wul4fY5O\ncAU4ETiv69j/qapHq+qHwI+BfYGjgTc21+VaYPdmPKN5CXBeVW2Axxzji5Ncm2QNcCQwr9m/Grgg\nyeuBh5t9VwP/M8k76FyLh3+/O0mSpPbq9RPPApxfVe/7nZ3JbOAZzdM5wH2Pcf5vus5ZQCfsHd7M\nZn4b2LHH+kazsfn6CFsw/qq6I8m/JTmSzqzt8d2HRzanc23+qqqW9VIsQJIdgXPozCzfkeR0/v3a\n/Ec6If7PgPcnOaCqzkjyNTpriq9O8tKqurnXOiRJkqaLXmdyrwAWJnkKQJInJnkWneUKFwAfpLPU\nADpB9/fWhnbZFfhVE3D3pTODC51Z3SOS7LnpNTbXX1XdC/yqa73tG4ArR7Ybh9H6/yzweeALVfVI\n1/7/1KzT3Qt4NnALsAx4S5LHNXXvk2Tnx3itbwBvav5x0D3GTTYF2l80yw8WNu22A/aoqm8B76Fz\nDeck2auq1lTVmcByOjPLkiRJM0ZPIbeq1gGnAZcnWU0nrM0FDgHOrKoLgAeTvKmq7qYzq7g2yVmj\ndHcZMCvJTXRuUrumeY27gJOALzVLGS5q2n8VOHbTjWcj+voL4Kympvl0biLbUt8C9tt041mz7xI6\nM9PnjWj7Ezrrj/8ZOLmqHqATiNcB1ydZC3yax5g5rqrLmr6Hm+UNp4w4fg+dfyyspROelzeHtgc+\n3yxhuAH426btO5vrvBp4qKlLkiRpxkiV9xyNV5JB4ONV9cKufUuBS6vq4r4V1qPBwcEaHh7udxmS\nJEljSrKiqgbHatfrmtwZI8l7gbfwu2txJUmStA2a8SE3yUvprCHudltVHdu9o6rOoLOMghH7T9iC\n1zoA+McRuzdW1WHj7UOSJEljm/Eht3n3g57fAWGcr7WGzhphSZIkTaKp/FhfSZIkaUoYciVJktQ6\nhlxJkiS1jiFXkiRJrWPIlSRJUusYciVJktQ6hlxJkiS1jiFXkiRJrWPIlSRJUusYciVJktQ6M/5j\nfQXr169n8eLF/S5DLTE0NNTvEiRJciZXkiRJ7WPIlSRJUusYciVJktQ6hlxJkiS1zowMuUlOSHJ2\nv+uQJEnS5JiRIVeSJEnt1qqQm2TnJF9LsirJ2iTHJTkkyfeafdcl2aVpPpDksiQ/TPLRrj6OTvL9\nJNcn+UKSOc3+25N8JMnKJMNJDkqyLMmtSU7uOv/UJMuTrE7ymO/LlWRukpuSfCbJjUkuT7JTc+zN\nTR+rknwxyexm/9Ikn0pyTZIfJ1mQ5HNNP0vHGsOI1z+pGcfwhg0ber30kiRJ25RWhVzgZcD6qjqw\nqvYHLgMuAv66qg4EXgL8tmk7HzgOOAA4LskeSZ4EnAa8pKoOAoaBd3f1/5Oqmg9cBSwFFgLPBRZD\nJ1wCewOHNv0fnOSIzdS7N/DJqpoH3AO8utn/pao6pKn5JuAvu855AnA48C7gEuDjwDzggCTzxzEG\nAKpqSVUNVtXg7NmzNz7A2DwAAAvwSURBVFOiJEnS9NO2D4NYA/yPJGcCl9IJjndW1XKAqvo1QBKA\nK6rq3ub5OuBZwG7AfsDVTZsdgO939X9J1+vMqar7gPuSbEyyG3B087ihaTeHTpD9zmPUe1tVrWy2\nVwBzm+39k3y4qWcOsKzrnK9WVSVZA/xbVa1pxnBjc/4zxhiDJElS67Uq5FbVD5IcBLwc+DDwzc00\n39i1/QidaxHgG1X12jHOeXTE+Y92nf+Rqvr0OEseWcNOzfZS4JiqWpXkBGDBFtTwyBhjkCRJar1W\nLVdIMgBsqKrPA2cBhwFPS3JIc3yXJJsL9tcAz0/yB037nZPsswUlLANO7FrH+/QkT9mKoewC3Jnk\nccDxW3hur2OQJEma9lo1k0tnfe1ZSR4FHgLeQmd29e+am7p+S2dd7qiq6q5m5vSfkjy+2X0a8IPx\nvHhVXZ7kOcD3m6UC9wOvB36+heP4AHAtcFfzdZfNN/+dGnoagyRJUhukqvpdg/psYGCgFi1a1O8y\n1BJDQ0P9LkGS1GJJVlTV4JjtDLkaHBys4eHhfpchSZI0pvGG3LYtV9jmJNkduGKUQ0dV1d1TXY8k\nSdJMYMidZE2Qnd/vOiRJkmaSVr27giRJkgSGXEmSJLWQIVeSJEmtY8iVJElS6xhyJUmS1DqGXEmS\nJLWOIVeSJEmtY8iVJElS6xhyJUmS1DqGXEmSJLWOH+sr1q9fz+LFi/tdhqaBoaGhfpcgSdK4OJMr\nSZKk1jHkSpIkqXUMuZIkSWodQ+40k+T+ftcgSZK0rTPkSpIkqXUMudNUku2SnJPk5iTfSPL1JAub\nYx9MsjzJ2iRLkqTf9UqSJE0lQ+709efAXGA/4A3A4V3Hzq6qQ6pqf2An4BUjT05yUpLhJMMbNmyY\ninolSZKmjCF3+noB8IWqerSqfgZ8q+vYi5Ncm2QNcCQwb+TJVbWkqgaranD27NlTVLIkSdLU8MMg\nWibJjsA5wGBV3ZHkdGDH/lYlSZI0tZzJnb6uBl7drM19KrCg2b8p0P4iyRxgYT+KkyRJ6idncqev\nLwJHAeuAO4DrgXur6p4knwHWAj8DlvevREmSpP4w5E4zVTWn+fpoklOq6v4kuwPXAWuaY6cBp/Wx\nTEmSpL4y5E5vlybZDdgB+G/NDWiSJEkzXqqq3zWozwYHB2t4eLjfZUiSJI0pyYqqGhyrnTeeSZIk\nqXUMuZIkSWodQ64kSZJax5ArSZKk1jHkSpIkqXUMuZIkSWodQ64kSZJax5ArSZKk1jHkSpIkqXUM\nuZIkSWodQ64kSZJax5ArSZKk1pnV7wLUf+vXr2fx4sX9LkN9MjQ01O8SJEmacM7kSpIkqXUMuZIk\nSWodQ64kSZJax5DbYklOSDLQ7zokSZKmmiG33U4ADLmSJGnGMeT2IMncJDcnuSDJTUkuTjI7yQeT\nLE+yNsmSdOyV5Pquc/fe9DzJ7Uk+kmRlkuEkByVZluTWJCd3nXNq0+/qJIu7argpyWeS3Jjk8iQ7\nJVkIDAIXNP3uNNXXR5IkqV8Mub37Q+CcqnoO8GvgrcDZVXVIVe0P7AS8oqpuBe5NMr85703AeV39\n/KSq5gNXAUuBhcBzgU1h9mhgb+BQYD5wcJIjmnP3Bj5ZVfOAe4BXV9XFwDBwfFXNr6rfdhed5KQm\nUA9v2LBhIq+HJElS3xlye3dHVV3dbH8eeAHw4iTXJlkDHAnMa45/FnhTku2B44D/3dXPJc3XNcC1\nVXVfVd0FbEyyG3B087gBuB7Yl064BbitqlY22yuAuWMVXVVLqmqwqgZnz569xYOWJEnalvlhEL2r\nUZ6fAwxW1R1JTgd2bI59ERgCvgmsqKq7u87b2Hx9tGt70/NZQICPVNWnu18sydwR7R+hM3ssSZI0\nYzmT27tnJjm82X4d8N1m+xdJ5tBZdgBAVT0ALAM+xe8uVRiPZcCJTZ8keXqSp4xxzn3ALlv4OpIk\nSdOeM7m9uwV4W5LPAevoBNgnAGuBnwHLR7S/ADgWuHxLXqSqLk/yHOD7SQDuB15PZ+b2sSwFzk3y\nW+DwketyJUmS2ipVI/+3XePVLBW4tLnBbLznnALsWlUfmKy6ttTAwEAtWrSo32WoT4aGhvpdgiRJ\n45ZkRVUNjtXOmdwplOTLwF50bkaTJEnSJHEmVwwODtbw8HC/y5AkSRrTeGdyvfFMkiRJrWPIlSRJ\nUusYciVJktQ6hlxJkiS1jiFXkiRJrWPIlSRJUuv4FmIiyX10PrltpnoS8It+F9FnM/0aOH7HP5PH\nD14Dxz+9xv+sqnryWI38MAgB3DKe95trqyTDM3n84DVw/I5/Jo8fvAaOv53jd7mCJEmSWseQK0mS\npNYx5ApgSb8L6LOZPn7wGjj+mW2mjx+8Bo6/hbzxTJIkSa3jTK4kSZJax5ArSZKk1jHktlySlyW5\nJcmPkrx3lOOPT3JRc/zaJHO7jr2v2X9LkpdOZd0TZWvHn2T3JN9Kcn+Ss6e67onSw/j/JMmKJGua\nr0dOde0TpYdrcGiSlc1jVZJjp7r2idDL74Dm+DObPwenTFXNE6mH7//cJL/t+hk4d6prnwg9/h3w\nR0m+n+TG5nfBjlNZ+0Tp4Wfg+K7v/8okjyaZP9X196qH8T8uyfnN9/6mJO+b6tp7VlU+WvoAtgdu\nBZ4N7ACsAvYb0eatwLnN9muAi5rt/Zr2jwf2bPrZvt9jmsLx7wy8ADgZOLvfY+nD+P8YGGi29wf+\ntd/j6cM1mA3MarafBvx80/Pp8uhl/F3HLwa+AJzS7/FM8fd/LrC232Po4/hnAauBA5vnu0+3vwN6\nvQYj2hwA3Nrv8Uzxz8DrgAub7dnA7cDcfo9pSx7O5LbbocCPqurHVfUgcCHwqhFtXgWc32xfDByV\nJM3+C6tqY1XdBvyo6W862erxV9Vvquq7wANTV+6E62X8N1TV+mb/jcBOSR4/JVVPrF6uwYaqerjZ\nvyMwHe/S7eV3AEmOAW6j8zMwHfU0/hboZfxHA6urahVAVd1dVY9MUd0TaaJ+Bl7bnDvd9DL+AnZO\nMgvYCXgQ+PXUlD0xDLnt9nTgjq7nP232jdqm+Qv9Xjr/Yh/Pudu6XsbfBhM1/lcD11fVxkmqczL1\ndA2SHJbkRmANcHJX6J0utnr8SeYA7wEWT0Gdk6XXPwN7JrkhyZVJXjjZxU6CXsa/D1BJliW5Psl/\nmYJ6J8NE/R48DvinSapxMvUy/ouB3wB3Aj8BPlZVv5zsgieSH+sr6TElmQecSWdWZ8apqmuBeUme\nA5yf5J+rajrP7m+J04GPV9X97ZnY3CJ3As+sqruTHAx8Jcm8qppWM1k9mEVnydYhwAbgiiQrquqK\n/pY19ZIcBmyoqrX9rmWKHQo8AgwATwCuSvIvVfXj/pY1fs7kttu/Ant0PX9Gs2/UNs1/SewK3D3O\nc7d1vYy/DXoaf5JnAF8G3lhVt056tZNjQn4Gquom4H4665Onk17Gfxjw0SS3A+8E/muSt092wRNs\nq8ffLNW6G6CqVtBZ17jPpFc8sXr5/v8U+E5V/aKqNgBfBw6a9Ion3kT8DngN03MWF3ob/+uAy6rq\noar6OXA1MDjpFU8gQ267LQf2TrJnkh3o/EG9ZESbS4C/aLYXAt+szirzS4DXNHdd7gnsDVw3RXVP\nlF7G3wZbPf4kuwFfA95bVVdPWcUTr5drsGfzC58kzwL2pXPjxXSy1eOvqhdW1dyqmgt8AvjvVTXd\n3mmkl+//k5NsD5Dk2XR+B06bGaxGL78DlwEHJJnd/Dl4EbBuiuqeSD39PZBkO+A/Mz3X40Jv4/8J\ncCRAkp2B5wI3T0nVE6Xfd775mNwH8HLgB3RmId7f7PsQ8Mpme0c6d07/iE6IfXbXue9vzrsF+NN+\nj6UP478d+CWdGbyfMuKO1Onw2NrxA6fRWYu1suvxlH6PZ4qvwRvo3HC1ErgeOKbfY5nK8Y/o43Sm\n4bsr9Pj9f/WI7/+f9XssU/39B17fXIO1wEf7PZY+XYMFwDX9HkM/xg/MafbfSOcfOKf2eyxb+vBj\nfSVJktQ6LleQJElS6xhyJUmS1DqGXEmSJLWOIVeSJEmtY8iVJElS6xhyJUmS1DqGXEmSJLXO/wM1\n99A0istCZwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "y8HzLcCBYiiv"
      },
      "source": [
        "## 2. Drop-Column Importance\n",
        "\n",
        "The best in theory, but too slow in practice"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DQAOlERnYiiw",
        "outputId": "ba2c3187-1123-477e-d370-5578d426c02c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "column  = 'quantity'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without quantity: 0.7771043771043771\n",
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Drop-Column Importance for quantity: 0.03644781144781151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "6Vu39wGkYiix"
      },
      "source": [
        "## 3. Permutation Importance\n",
        "\n",
        "Permutation Importance is a good compromise between Feature Importance based on impurity reduction (which is the fastest) and Drop Column Importance (which is the \"best.\")\n",
        "\n",
        "[The ELI5 library documentation explains,](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html)\n",
        "\n",
        "> Importance can be measured by looking at how much the score (accuracy, F1, R^2, etc. - any score we’re interested in) decreases when a feature is not available.\n",
        ">\n",
        "> To do that one can remove feature from the dataset, re-train the estimator and check the score. But it requires re-training an estimator for each feature, which can be computationally intensive. ...\n",
        ">\n",
        ">To avoid re-training the estimator we can remove a feature only from the test part of the dataset, and compute score without using this feature. It doesn’t work as-is, because estimators expect feature to be present. So instead of removing a feature we can replace it with random noise - feature column is still there, but it no longer contains useful information. This method works if noise is drawn from the same distribution as original feature values (as otherwise estimator may fail). The simplest way to get such noise is to shuffle values for a feature, i.e. use other examples’ feature values - this is how permutation importance is computed.\n",
        ">\n",
        ">The method is most suitable for computing feature importances when a number of columns (features) is not huge; it can be resource-intensive otherwise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GYCiEx7zYiiy"
      },
      "source": [
        "### Do-It-Yourself way, for intuition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TksOf_n2Yiiy",
        "outputId": "aab179c4-4af1-4bc1-d9e2-6aa451ea7916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "feature = 'quantity'\n",
        "X_val[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     insufficient\n",
              "47666    insufficient\n",
              "2538           enough\n",
              "53117          enough\n",
              "51817          enough\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpbrM00z-5uS",
        "colab_type": "code",
        "outputId": "4f17e84c-a8f0-48b1-87fb-6cf314c8e987",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "X_val[feature].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVeoim9q-800",
        "colab_type": "code",
        "outputId": "1af5c11b-7fb5-4f27-ad04-13a8f081be9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])\n",
        "X_val_permuted[feature].head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3290     enough\n",
              "47666    enough\n",
              "2538     enough\n",
              "53117    enough\n",
              "51817       dry\n",
              "Name: quantity, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7cdI8z0_boA",
        "colab_type": "code",
        "outputId": "5c5d249c-571f-497a-dd0e-a2ff7e9d2f7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "X_val_permuted['quantity'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "enough          6619\n",
              "insufficient    2976\n",
              "dry             1325\n",
              "seasonal         806\n",
              "unknown          154\n",
              "Name: quantity, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2o5T_F2_h71",
        "colab_type": "code",
        "outputId": "c4b026b6-97ea-4992-953f-8fd3d892a34a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Notice that we don't need to refit the pipeline here!\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation Accuracy with {feature}: {score_with}')\n",
        "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation Importance: {score_with - score_permuted}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy with quantity: 0.8135521885521886\n",
            "Validation Accuracy with quantity permuted: 0.7127104377104377\n",
            "Permutation Importance: 0.10084175084175084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAMpWPZI_0T3",
        "colab_type": "code",
        "outputId": "4dace6a0-4ff9-4b58-995d-85f0fa863b1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "feature = 'wpt_name'\n",
        "X_val_permuted = X_val.copy()\n",
        "X_val_permuted[feature] = np.random.permutation(X_val[feature])\n",
        "score_permuted = pipeline.score(X_val_permuted, y_val)\n",
        "\n",
        "print(f'Validation Accuracy with {feature}: {score_with}')\n",
        "print(f'Validation Accuracy with {feature} permuted: {score_permuted}')\n",
        "print(f'Permutation Importance: {score_with - score_permuted}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy with wpt_name: 0.8135521885521886\n",
            "Validation Accuracy with wpt_name permuted: 0.8123737373737374\n",
            "Permutation Importance: 0.0011784511784511675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0LYk19SNYii7"
      },
      "source": [
        "### With eli5 library\n",
        "\n",
        "For more documentation on using this library, see:\n",
        "- [eli5.sklearn.PermutationImportance](https://eli5.readthedocs.io/en/latest/autodocs/sklearn.html#eli5.sklearn.permutation_importance.PermutationImportance)\n",
        "- [eli5.show_weights](https://eli5.readthedocs.io/en/latest/autodocs/eli5.html#eli5.show_weights)\n",
        "- [scikit-learn user guide, `scoring` parameter](https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules)\n",
        "\n",
        "eli5 doesn't work with pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpSemTkFFP8i",
        "colab_type": "code",
        "outputId": "6e00c24f-cf01-4e63-e7d1-87dd11674fdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median')\n",
        ")\n",
        "\n",
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiO_EqahBEpm",
        "colab_type": "code",
        "outputId": "57967a19-9902-434b-f29c-aa6e097b67f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        }
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "permuter = PermutationImportance(\n",
        "    model, scoring='accuracy', n_iter=2, random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)\n",
        "feature_names = X_val.columns.tolist()\n",
        "eli5.show_weights(\n",
        "    permuter, \n",
        "    top=None,  # show the permutation importances for all features\n",
        "    feature_names=feature_names\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.1005\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quantity\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0105\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                amount_tsh\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.92%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0104\n",
              "                \n",
              "                    &plusmn; 0.0012\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.02%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0100\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.15%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0096\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.74%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0075\n",
              "                \n",
              "                    &plusmn; 0.0019\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 96.89%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0070\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                waterpoint_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.09%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0064\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.08%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0035\n",
              "                \n",
              "                    &plusmn; 0.0034\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.28%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0030\n",
              "                \n",
              "                    &plusmn; 0.0035\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.33%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0029\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                public_meeting\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                subvillage\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.36%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0028\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                payment\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0023\n",
              "                \n",
              "                    &plusmn; 0.0018\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                day_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.80%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0018\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0016\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.94%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0015\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                district_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0014\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0011\n",
              "                \n",
              "                    &plusmn; 0.0016\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.25%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                longitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0009\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                extraction_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0006\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ward\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                year_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.35%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0008\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                wpt_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.37%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                water_quality\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                years_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.40%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0007\n",
              "                \n",
              "                    &plusmn; 0.0005\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                permit\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.42%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0004\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                funder\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.45%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0006\n",
              "                \n",
              "                    &plusmn; 0.0010\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_class\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0009\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                lga\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0014\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                region_code\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.51%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0024\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.54%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0005\n",
              "                \n",
              "                    &plusmn; 0.0021\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                month_recorded\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.57%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0004\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                construction_year_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.63%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                num_private\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.70%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0003\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                population_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 99.81%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0001\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                latitude_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.91%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0000\n",
              "                \n",
              "                    &plusmn; 0.0001\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                source_type\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_name\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                scheme_management\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0003\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                management_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.77%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0002\n",
              "                \n",
              "                    &plusmn; 0.0007\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                gps_height_MISSING\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0008\n",
              "                \n",
              "                    &plusmn; 0.0013\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                installer\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 99.27%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0009\n",
              "                \n",
              "                    &plusmn; 0.0011\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                quality_group\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 98.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                -0.0019\n",
              "                \n",
              "                    &plusmn; 0.0008\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                basin\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "q07yW9k-Yii8"
      },
      "source": [
        "### We can use importances for feature selection\n",
        "\n",
        "For example, we can remove features with zero importance. The model trains faster and the score does not decrease."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tZrPFyEMYii9",
        "outputId": "5285db0c-c9cc-4869-f864-0a5b018d8972",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print('Shape before removing features:', X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape before removing features: (47520, 45)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKk28u7OEku_",
        "colab_type": "code",
        "outputId": "b857e382-6d15-4a7d-955e-359434a075a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > 0\n",
        "features = X_train.columns[mask]\n",
        "X_train = X_train[features]\n",
        "print('Shape after removing features:', X_train.shape)\n",
        "\n",
        "X_val = X_val[features]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape after removing features: (47520, 37)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zWG94LtFFIp",
        "colab_type": "code",
        "outputId": "1bbeb11a-d746-47db-c7e9-c3c545b49bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "%%time\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.8138047138047138\n",
            "CPU times: user 20.9 s, sys: 119 ms, total: 21 s\n",
            "Wall time: 11.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fl67bCR7WY6j",
        "colab_type": "text"
      },
      "source": [
        "## Use xgboost for gradient boosting\n",
        "\n",
        "#### [XGBoost Python API Reference: Scikit-Learn API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#module-xgboost.sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsnJRKjfWYph",
        "colab_type": "code",
        "outputId": "d44d6b58-ba03-4aaf-a428-3756ff75193c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import xgboost as xgb\n",
        "xgb.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.90'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJTjf6-_IVbJ",
        "colab_type": "code",
        "outputId": "cf632986-9b10-42ba-b0d7-b74d6335adda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['funder', 'wpt_name', 'subvillage',\n",
              "                                      'region', 'lga', 'ward', 'public_meeting',\n",
              "                                      'permit', 'extraction_type',\n",
              "                                      'extraction_type_group',\n",
              "                                      'extraction_type_class', 'management',\n",
              "                                      'payment', 'water_quality', 'quantity',\n",
              "                                      'source', 'source_class',\n",
              "                                      'waterpoint_type',\n",
              "                                      'waterpoint_type_group'],\n",
              "                                drop_invariant=Fals...\n",
              "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uDGVpyhJKrh",
        "colab_type": "code",
        "outputId": "6dd3f519-4d27-481e-b9f0-5167b1359254",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.7454545454545455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubb7Ot6OZcK1",
        "colab_type": "text"
      },
      "source": [
        "### Understand the difference between boosting & bagging\n",
        "\n",
        "Boosting (used by Gradient Boosting) is different than Bagging (used by Random Forests). \n",
        "\n",
        "[_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8.2.3, Boosting:\n",
        "\n",
        ">Recall that bagging involves creating multiple copies of the original training data set using the bootstrap, fitting a separate decision tree to each copy, and then combining all of the trees in order to create a single predictive model.\n",
        ">\n",
        ">**Boosting works in a similar way, except that the trees are grown _sequentially_: each tree is grown using information from previously grown trees.**\n",
        ">\n",
        ">Unlike fitting a single large decision tree to the data, which amounts to _fitting the data hard_ and potentially overfitting, the boosting approach instead _learns slowly._ Given the current model, we fit a decision tree to the residuals from the model.\n",
        ">\n",
        ">We then add this new decision tree into the fitted function in order to update the residuals. Each of these trees can be rather small, with just a few terminal nodes. **By fitting small trees to the residuals, we slowly improve fˆ in areas where it does not perform well.**\n",
        ">\n",
        ">Note that in boosting, unlike in bagging, the construction of each tree depends strongly on the trees that have already been grown."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCjVSlD_XJr2",
        "colab_type": "text"
      },
      "source": [
        "#### [Avoid Overfitting By Early Stopping With XGBoost In Python](https://machinelearningmastery.com/avoid-overfitting-by-early-stopping-with-xgboost-in-python/)\n",
        "\n",
        "Why is early stopping better than a For loop, or GridSearchCV, to optimize `n_estimators`?\n",
        "\n",
        "With early stopping, if `n_iterations` is our number of iterations, then we fit `n_iterations` decision trees.\n",
        "\n",
        "With a for loop, or GridSearchCV, we'd fit `sum(range(1,n_rounds+1))` trees.\n",
        "\n",
        "But it doesn't work well with pipelines. You may need to re-run multiple times with different values of other parameters such as `max_depth` and `learning_rate`.\n",
        "\n",
        "#### XGBoost parameters\n",
        "- [Notes on parameter tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html)\n",
        "- [Parameters documentation](https://xgboost.readthedocs.io/en/latest/parameter.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNX3IKftXBFS",
        "colab_type": "code",
        "outputId": "2b1083a2-4108-4e20-c9d3-98c0bebe96b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "X_train.shape, X_val.shape, X_train_encoded.shape, X_val_encoded.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((47520, 37), (11880, 37), (47520, 37), (11880, 37))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROt3Nz-aM9H_",
        "colab_type": "code",
        "outputId": "f84288e4-48fc-49f2-ed9e-226871f74e65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "eval_set = [(X_train_encoded, y_train), \n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000, # <= 1000 trees, depends on early stopping\n",
        "    max_depth=7,       # try deeper trees because of high cardinality categoricals\n",
        "    learning_rate=0.5, # try higher learning rate\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "model.fit(X_train_encoded, y_train, early_stopping_rounds=50, \n",
        "          eval_metric='merror', eval_set=eval_set)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.250821\tvalidation_1-merror:0.261027\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.235774\tvalidation_1-merror:0.246549\n",
            "[2]\tvalidation_0-merror:0.233838\tvalidation_1-merror:0.244865\n",
            "[3]\tvalidation_0-merror:0.225105\tvalidation_1-merror:0.239141\n",
            "[4]\tvalidation_0-merror:0.21814\tvalidation_1-merror:0.233923\n",
            "[5]\tvalidation_0-merror:0.210164\tvalidation_1-merror:0.230303\n",
            "[6]\tvalidation_0-merror:0.205598\tvalidation_1-merror:0.226178\n",
            "[7]\tvalidation_0-merror:0.201599\tvalidation_1-merror:0.223232\n",
            "[8]\tvalidation_0-merror:0.19798\tvalidation_1-merror:0.221465\n",
            "[9]\tvalidation_0-merror:0.195265\tvalidation_1-merror:0.220875\n",
            "[10]\tvalidation_0-merror:0.191898\tvalidation_1-merror:0.21633\n",
            "[11]\tvalidation_0-merror:0.189878\tvalidation_1-merror:0.215909\n",
            "[12]\tvalidation_0-merror:0.186595\tvalidation_1-merror:0.213721\n",
            "[13]\tvalidation_0-merror:0.184133\tvalidation_1-merror:0.212626\n",
            "[14]\tvalidation_0-merror:0.181082\tvalidation_1-merror:0.211785\n",
            "[15]\tvalidation_0-merror:0.178367\tvalidation_1-merror:0.211448\n",
            "[16]\tvalidation_0-merror:0.176452\tvalidation_1-merror:0.210606\n",
            "[17]\tvalidation_0-merror:0.173822\tvalidation_1-merror:0.209512\n",
            "[18]\tvalidation_0-merror:0.171928\tvalidation_1-merror:0.20968\n",
            "[19]\tvalidation_0-merror:0.17016\tvalidation_1-merror:0.208586\n",
            "[20]\tvalidation_0-merror:0.168308\tvalidation_1-merror:0.209091\n",
            "[21]\tvalidation_0-merror:0.164962\tvalidation_1-merror:0.207744\n",
            "[22]\tvalidation_0-merror:0.1633\tvalidation_1-merror:0.208249\n",
            "[23]\tvalidation_0-merror:0.161279\tvalidation_1-merror:0.207828\n",
            "[24]\tvalidation_0-merror:0.160038\tvalidation_1-merror:0.207239\n",
            "[25]\tvalidation_0-merror:0.157891\tvalidation_1-merror:0.20665\n",
            "[26]\tvalidation_0-merror:0.15686\tvalidation_1-merror:0.206313\n",
            "[27]\tvalidation_0-merror:0.155913\tvalidation_1-merror:0.206313\n",
            "[28]\tvalidation_0-merror:0.154419\tvalidation_1-merror:0.206061\n",
            "[29]\tvalidation_0-merror:0.15141\tvalidation_1-merror:0.204882\n",
            "[30]\tvalidation_0-merror:0.1496\tvalidation_1-merror:0.204798\n",
            "[31]\tvalidation_0-merror:0.148106\tvalidation_1-merror:0.204377\n",
            "[32]\tvalidation_0-merror:0.146023\tvalidation_1-merror:0.203704\n",
            "[33]\tvalidation_0-merror:0.144971\tvalidation_1-merror:0.20404\n",
            "[34]\tvalidation_0-merror:0.144339\tvalidation_1-merror:0.203956\n",
            "[35]\tvalidation_0-merror:0.143161\tvalidation_1-merror:0.203367\n",
            "[36]\tvalidation_0-merror:0.141877\tvalidation_1-merror:0.202778\n",
            "[37]\tvalidation_0-merror:0.139731\tvalidation_1-merror:0.202525\n",
            "[38]\tvalidation_0-merror:0.1367\tvalidation_1-merror:0.202441\n",
            "[39]\tvalidation_0-merror:0.135838\tvalidation_1-merror:0.201852\n",
            "[40]\tvalidation_0-merror:0.134428\tvalidation_1-merror:0.20202\n",
            "[41]\tvalidation_0-merror:0.133838\tvalidation_1-merror:0.202189\n",
            "[42]\tvalidation_0-merror:0.131608\tvalidation_1-merror:0.202609\n",
            "[43]\tvalidation_0-merror:0.129756\tvalidation_1-merror:0.203283\n",
            "[44]\tvalidation_0-merror:0.128283\tvalidation_1-merror:0.205135\n",
            "[45]\tvalidation_0-merror:0.126136\tvalidation_1-merror:0.203199\n",
            "[46]\tvalidation_0-merror:0.124116\tvalidation_1-merror:0.202525\n",
            "[47]\tvalidation_0-merror:0.122012\tvalidation_1-merror:0.202946\n",
            "[48]\tvalidation_0-merror:0.121549\tvalidation_1-merror:0.202694\n",
            "[49]\tvalidation_0-merror:0.120812\tvalidation_1-merror:0.20362\n",
            "[50]\tvalidation_0-merror:0.118897\tvalidation_1-merror:0.202609\n",
            "[51]\tvalidation_0-merror:0.117908\tvalidation_1-merror:0.203367\n",
            "[52]\tvalidation_0-merror:0.116162\tvalidation_1-merror:0.204461\n",
            "[53]\tvalidation_0-merror:0.115278\tvalidation_1-merror:0.20404\n",
            "[54]\tvalidation_0-merror:0.114099\tvalidation_1-merror:0.203872\n",
            "[55]\tvalidation_0-merror:0.112647\tvalidation_1-merror:0.203872\n",
            "[56]\tvalidation_0-merror:0.111406\tvalidation_1-merror:0.204882\n",
            "[57]\tvalidation_0-merror:0.110627\tvalidation_1-merror:0.204966\n",
            "[58]\tvalidation_0-merror:0.10928\tvalidation_1-merror:0.205387\n",
            "[59]\tvalidation_0-merror:0.108018\tvalidation_1-merror:0.205387\n",
            "[60]\tvalidation_0-merror:0.106755\tvalidation_1-merror:0.206313\n",
            "[61]\tvalidation_0-merror:0.10564\tvalidation_1-merror:0.205724\n",
            "[62]\tvalidation_0-merror:0.102946\tvalidation_1-merror:0.204377\n",
            "[63]\tvalidation_0-merror:0.102378\tvalidation_1-merror:0.204882\n",
            "[64]\tvalidation_0-merror:0.101178\tvalidation_1-merror:0.204798\n",
            "[65]\tvalidation_0-merror:0.100421\tvalidation_1-merror:0.204461\n",
            "[66]\tvalidation_0-merror:0.098885\tvalidation_1-merror:0.204125\n",
            "[67]\tvalidation_0-merror:0.097685\tvalidation_1-merror:0.203535\n",
            "[68]\tvalidation_0-merror:0.097117\tvalidation_1-merror:0.201936\n",
            "[69]\tvalidation_0-merror:0.096843\tvalidation_1-merror:0.201515\n",
            "[70]\tvalidation_0-merror:0.095707\tvalidation_1-merror:0.202104\n",
            "[71]\tvalidation_0-merror:0.094697\tvalidation_1-merror:0.202609\n",
            "[72]\tvalidation_0-merror:0.093434\tvalidation_1-merror:0.203114\n",
            "[73]\tvalidation_0-merror:0.092382\tvalidation_1-merror:0.20303\n",
            "[74]\tvalidation_0-merror:0.091709\tvalidation_1-merror:0.203199\n",
            "[75]\tvalidation_0-merror:0.090657\tvalidation_1-merror:0.203367\n",
            "[76]\tvalidation_0-merror:0.089415\tvalidation_1-merror:0.203199\n",
            "[77]\tvalidation_0-merror:0.088173\tvalidation_1-merror:0.20303\n",
            "[78]\tvalidation_0-merror:0.087269\tvalidation_1-merror:0.202946\n",
            "[79]\tvalidation_0-merror:0.086343\tvalidation_1-merror:0.202946\n",
            "[80]\tvalidation_0-merror:0.085354\tvalidation_1-merror:0.20404\n",
            "[81]\tvalidation_0-merror:0.084407\tvalidation_1-merror:0.203283\n",
            "[82]\tvalidation_0-merror:0.08306\tvalidation_1-merror:0.203872\n",
            "[83]\tvalidation_0-merror:0.082681\tvalidation_1-merror:0.203704\n",
            "[84]\tvalidation_0-merror:0.082218\tvalidation_1-merror:0.203788\n",
            "[85]\tvalidation_0-merror:0.080703\tvalidation_1-merror:0.20303\n",
            "[86]\tvalidation_0-merror:0.079503\tvalidation_1-merror:0.203114\n",
            "[87]\tvalidation_0-merror:0.078346\tvalidation_1-merror:0.20362\n",
            "[88]\tvalidation_0-merror:0.076747\tvalidation_1-merror:0.203367\n",
            "[89]\tvalidation_0-merror:0.075442\tvalidation_1-merror:0.203114\n",
            "[90]\tvalidation_0-merror:0.075231\tvalidation_1-merror:0.20303\n",
            "[91]\tvalidation_0-merror:0.074306\tvalidation_1-merror:0.201684\n",
            "[92]\tvalidation_0-merror:0.073611\tvalidation_1-merror:0.201431\n",
            "[93]\tvalidation_0-merror:0.073064\tvalidation_1-merror:0.201599\n",
            "[94]\tvalidation_0-merror:0.072769\tvalidation_1-merror:0.201431\n",
            "[95]\tvalidation_0-merror:0.071949\tvalidation_1-merror:0.200673\n",
            "[96]\tvalidation_0-merror:0.071107\tvalidation_1-merror:0.200842\n",
            "[97]\tvalidation_0-merror:0.070812\tvalidation_1-merror:0.200673\n",
            "[98]\tvalidation_0-merror:0.070434\tvalidation_1-merror:0.200421\n",
            "[99]\tvalidation_0-merror:0.069907\tvalidation_1-merror:0.200337\n",
            "[100]\tvalidation_0-merror:0.068582\tvalidation_1-merror:0.200673\n",
            "[101]\tvalidation_0-merror:0.067887\tvalidation_1-merror:0.200758\n",
            "[102]\tvalidation_0-merror:0.066961\tvalidation_1-merror:0.201094\n",
            "[103]\tvalidation_0-merror:0.066014\tvalidation_1-merror:0.201768\n",
            "[104]\tvalidation_0-merror:0.065572\tvalidation_1-merror:0.201599\n",
            "[105]\tvalidation_0-merror:0.06452\tvalidation_1-merror:0.200842\n",
            "[106]\tvalidation_0-merror:0.063594\tvalidation_1-merror:0.200505\n",
            "[107]\tvalidation_0-merror:0.06311\tvalidation_1-merror:0.2\n",
            "[108]\tvalidation_0-merror:0.061911\tvalidation_1-merror:0.2\n",
            "[109]\tvalidation_0-merror:0.06109\tvalidation_1-merror:0.199411\n",
            "[110]\tvalidation_0-merror:0.060417\tvalidation_1-merror:0.199242\n",
            "[111]\tvalidation_0-merror:0.059701\tvalidation_1-merror:0.199158\n",
            "[112]\tvalidation_0-merror:0.058944\tvalidation_1-merror:0.199663\n",
            "[113]\tvalidation_0-merror:0.057765\tvalidation_1-merror:0.199832\n",
            "[114]\tvalidation_0-merror:0.056797\tvalidation_1-merror:0.199916\n",
            "[115]\tvalidation_0-merror:0.056334\tvalidation_1-merror:0.199663\n",
            "[116]\tvalidation_0-merror:0.055619\tvalidation_1-merror:0.200253\n",
            "[117]\tvalidation_0-merror:0.054861\tvalidation_1-merror:0.200337\n",
            "[118]\tvalidation_0-merror:0.054335\tvalidation_1-merror:0.200673\n",
            "[119]\tvalidation_0-merror:0.05383\tvalidation_1-merror:0.200589\n",
            "[120]\tvalidation_0-merror:0.053157\tvalidation_1-merror:0.200084\n",
            "[121]\tvalidation_0-merror:0.052567\tvalidation_1-merror:0.200421\n",
            "[122]\tvalidation_0-merror:0.052146\tvalidation_1-merror:0.199832\n",
            "[123]\tvalidation_0-merror:0.051347\tvalidation_1-merror:0.199832\n",
            "[124]\tvalidation_0-merror:0.050968\tvalidation_1-merror:0.199916\n",
            "[125]\tvalidation_0-merror:0.050694\tvalidation_1-merror:0.200589\n",
            "[126]\tvalidation_0-merror:0.050337\tvalidation_1-merror:0.199916\n",
            "[127]\tvalidation_0-merror:0.049916\tvalidation_1-merror:0.200337\n",
            "[128]\tvalidation_0-merror:0.049285\tvalidation_1-merror:0.2\n",
            "[129]\tvalidation_0-merror:0.048611\tvalidation_1-merror:0.200505\n",
            "[130]\tvalidation_0-merror:0.047643\tvalidation_1-merror:0.201094\n",
            "[131]\tvalidation_0-merror:0.047096\tvalidation_1-merror:0.200842\n",
            "[132]\tvalidation_0-merror:0.046359\tvalidation_1-merror:0.200421\n",
            "[133]\tvalidation_0-merror:0.045833\tvalidation_1-merror:0.200084\n",
            "[134]\tvalidation_0-merror:0.045076\tvalidation_1-merror:0.200337\n",
            "[135]\tvalidation_0-merror:0.044318\tvalidation_1-merror:0.200421\n",
            "[136]\tvalidation_0-merror:0.043897\tvalidation_1-merror:0.200168\n",
            "[137]\tvalidation_0-merror:0.043013\tvalidation_1-merror:0.199158\n",
            "[138]\tvalidation_0-merror:0.042256\tvalidation_1-merror:0.199242\n",
            "[139]\tvalidation_0-merror:0.041877\tvalidation_1-merror:0.199158\n",
            "[140]\tvalidation_0-merror:0.041393\tvalidation_1-merror:0.19899\n",
            "[141]\tvalidation_0-merror:0.041035\tvalidation_1-merror:0.198737\n",
            "[142]\tvalidation_0-merror:0.040678\tvalidation_1-merror:0.198232\n",
            "[143]\tvalidation_0-merror:0.040425\tvalidation_1-merror:0.198906\n",
            "[144]\tvalidation_0-merror:0.040067\tvalidation_1-merror:0.199242\n",
            "[145]\tvalidation_0-merror:0.039268\tvalidation_1-merror:0.199158\n",
            "[146]\tvalidation_0-merror:0.038847\tvalidation_1-merror:0.200168\n",
            "[147]\tvalidation_0-merror:0.038384\tvalidation_1-merror:0.200337\n",
            "[148]\tvalidation_0-merror:0.037942\tvalidation_1-merror:0.200505\n",
            "[149]\tvalidation_0-merror:0.03771\tvalidation_1-merror:0.200673\n",
            "[150]\tvalidation_0-merror:0.037332\tvalidation_1-merror:0.200421\n",
            "[151]\tvalidation_0-merror:0.036553\tvalidation_1-merror:0.199411\n",
            "[152]\tvalidation_0-merror:0.036153\tvalidation_1-merror:0.199579\n",
            "[153]\tvalidation_0-merror:0.035922\tvalidation_1-merror:0.199495\n",
            "[154]\tvalidation_0-merror:0.035522\tvalidation_1-merror:0.198906\n",
            "[155]\tvalidation_0-merror:0.035164\tvalidation_1-merror:0.199832\n",
            "[156]\tvalidation_0-merror:0.035101\tvalidation_1-merror:0.200253\n",
            "[157]\tvalidation_0-merror:0.03468\tvalidation_1-merror:0.201431\n",
            "[158]\tvalidation_0-merror:0.03428\tvalidation_1-merror:0.200421\n",
            "[159]\tvalidation_0-merror:0.034112\tvalidation_1-merror:0.200337\n",
            "[160]\tvalidation_0-merror:0.033796\tvalidation_1-merror:0.2\n",
            "[161]\tvalidation_0-merror:0.033418\tvalidation_1-merror:0.2\n",
            "[162]\tvalidation_0-merror:0.032618\tvalidation_1-merror:0.199916\n",
            "[163]\tvalidation_0-merror:0.032281\tvalidation_1-merror:0.200084\n",
            "[164]\tvalidation_0-merror:0.031566\tvalidation_1-merror:0.200337\n",
            "[165]\tvalidation_0-merror:0.031418\tvalidation_1-merror:0.200589\n",
            "[166]\tvalidation_0-merror:0.031166\tvalidation_1-merror:0.200337\n",
            "[167]\tvalidation_0-merror:0.030913\tvalidation_1-merror:0.200589\n",
            "[168]\tvalidation_0-merror:0.030766\tvalidation_1-merror:0.200421\n",
            "[169]\tvalidation_0-merror:0.030429\tvalidation_1-merror:0.20101\n",
            "[170]\tvalidation_0-merror:0.030135\tvalidation_1-merror:0.20101\n",
            "[171]\tvalidation_0-merror:0.029419\tvalidation_1-merror:0.200337\n",
            "[172]\tvalidation_0-merror:0.029019\tvalidation_1-merror:0.201515\n",
            "[173]\tvalidation_0-merror:0.028662\tvalidation_1-merror:0.20101\n",
            "[174]\tvalidation_0-merror:0.028577\tvalidation_1-merror:0.200926\n",
            "[175]\tvalidation_0-merror:0.028451\tvalidation_1-merror:0.200842\n",
            "[176]\tvalidation_0-merror:0.028136\tvalidation_1-merror:0.201178\n",
            "[177]\tvalidation_0-merror:0.027462\tvalidation_1-merror:0.201599\n",
            "[178]\tvalidation_0-merror:0.027378\tvalidation_1-merror:0.202104\n",
            "[179]\tvalidation_0-merror:0.027273\tvalidation_1-merror:0.201768\n",
            "[180]\tvalidation_0-merror:0.026747\tvalidation_1-merror:0.201515\n",
            "[181]\tvalidation_0-merror:0.026431\tvalidation_1-merror:0.200842\n",
            "[182]\tvalidation_0-merror:0.026178\tvalidation_1-merror:0.201178\n",
            "[183]\tvalidation_0-merror:0.025631\tvalidation_1-merror:0.201599\n",
            "[184]\tvalidation_0-merror:0.025295\tvalidation_1-merror:0.201347\n",
            "[185]\tvalidation_0-merror:0.024684\tvalidation_1-merror:0.201515\n",
            "[186]\tvalidation_0-merror:0.024579\tvalidation_1-merror:0.201347\n",
            "[187]\tvalidation_0-merror:0.024053\tvalidation_1-merror:0.201515\n",
            "[188]\tvalidation_0-merror:0.023464\tvalidation_1-merror:0.201768\n",
            "[189]\tvalidation_0-merror:0.022854\tvalidation_1-merror:0.200842\n",
            "[190]\tvalidation_0-merror:0.022601\tvalidation_1-merror:0.201263\n",
            "[191]\tvalidation_0-merror:0.022475\tvalidation_1-merror:0.20101\n",
            "[192]\tvalidation_0-merror:0.022264\tvalidation_1-merror:0.201263\n",
            "Stopping. Best iteration:\n",
            "[142]\tvalidation_0-merror:0.040678\tvalidation_1-merror:0.198232\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.5, max_delta_step=0, max_depth=7,\n",
              "              min_child_weight=1, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYhql82BO9V0",
        "colab_type": "code",
        "outputId": "085e7701-2646-4adf-c789-967151330d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "plt.ylim((0.18, 0.22)) # Zoom in\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAELCAYAAAARNxsIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCyrGGGPCxoKKMcaYsPl/zJp0lYAcx1kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7-ml6BhRRf",
        "colab_type": "text"
      },
      "source": [
        "## Try adjusting these hyperparameters\n",
        "\n",
        "#### Random Forest\n",
        "- class_weight (for imbalanced classes)\n",
        "- max_depth (usually high, can try decreasing)\n",
        "- n_estimators (too low underfits, too high wastes time)\n",
        "- min_samples_leaf (increase if overfitting)\n",
        "- max_features (decrease for more diverse trees)\n",
        "\n",
        "#### Xgboost\n",
        "- scale_pos_weight (for imbalanced classes)\n",
        "- max_depth (usually low, can try increasing)\n",
        "- n_estimators (too low underfits, too high wastes time/overfits) — Use Early Stopping!\n",
        "- learning_rate (too low underfits, too high overfits)\n",
        "\n",
        "For more ideas, see [Notes on Parameter Tuning](https://xgboost.readthedocs.io/en/latest/tutorials/param_tuning.html) and [DART booster](https://xgboost.readthedocs.io/en/latest/tutorials/dart.html)."
      ]
    }
  ]
}