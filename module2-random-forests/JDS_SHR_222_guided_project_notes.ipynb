{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3pUeCRcQZdm"
      },
      "source": [
        "# BloomTech Data Science\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvWhcow-dvS8"
      },
      "source": [
        "# Random Forests\n",
        "\n",
        "- use scikit-learn for **random forests**\n",
        "- do **ordinal encoding** with high-cardinality categoricals\n",
        "- understand how categorical encodings affect trees differently compared to linear models\n",
        "- understand how tree ensembles reduce overfitting compared to a single decision tree with unlimited depth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkD8tqS_evY_"
      },
      "source": [
        "%%capture\n",
        "\n",
        "!pip install category_encoders==2.*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiJT7wGsuXcG"
      },
      "source": [
        "from category_encoders import OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUmaaCmCprYw"
      },
      "source": [
        "# Downloading the Tanzania Waterpump Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkdEatMkUKa1"
      },
      "source": [
        "Make sure  you only use the dataset that is available through the **DS** **Kaggle Competition**. DO NOT USE any other Tanzania waterpump datasets that you might find online.\n",
        "\n",
        "There are two ways you can get the dataset. Make sure you have joined the competition first!:\n",
        "\n",
        "1. You can download the dataset directly by accessing the challenge and the files through the Kaggle Competition URL on Canvas (make sure you have joined the competition!)\n",
        "\n",
        "2. Use the Kaggle API using the code in the following cells. This article provides helpful information on how to fetch your Kaggle Dataset into Google Colab using the Kaggle API.\n",
        "\n",
        "> https://medium.com/analytics-vidhya/how-to-fetch-kaggle-datasets-into-google-colab-ea682569851a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6TZ5nDFYkCa"
      },
      "source": [
        "# Using Kaggle API to download datset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2e6fPUATxLZ",
        "outputId": "b8cb2a8b-707c-4da8-e5b6-ff9b88f48493"
      },
      "source": [
        "# mounting your google drive on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYSpUv9uYBAo",
        "outputId": "2e6a88bf-6b0b-4a8e-aeac-e0919d4a78fb"
      },
      "source": [
        "#change your working directory, if you want to or have already saved your kaggle dataset on google drive.\n",
        "%cd /content/gdrive/My Drive/Kaggle\n",
        "# update it to your folder location on drive that contians the dataset and/or kaggle API token json file."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXChvgdZYb_t"
      },
      "source": [
        "# Download your Kaggle Dataset, if you haven't already done so.\n",
        "# import os\n",
        "# os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\"\n",
        "# !kaggle competitions download -c bloomtech-water-pump-challenge"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB84qgRRYdDF"
      },
      "source": [
        "# Unzip your Kaggle dataset, if you haven't already done so.\n",
        "# !unzip \\*.zip  && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eag2zYiQYf6q",
        "outputId": "f473e99f-41fd-4db3-c689-d98dd9b595e9"
      },
      "source": [
        "# List all files in your Kaggle folder on your google drive.\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\t    sample_submission.csv  train_features.csv\n",
            "new_submission.csv  test_features.csv\t   train_labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCBYPw7kd1AN"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB03VuwJOvhF"
      },
      "source": [
        "def wrangle(fm_path, tv_path=None):\n",
        "  if tv_path:\n",
        "    df = pd.merge(pd.read_csv(fm_path,\n",
        "                              na_values=[0, -2.000000e-08],\n",
        "                              parse_dates=['date_recorded']),\n",
        "                  pd.read_csv(tv_path)).set_index('id')\n",
        "  else:\n",
        "    df = pd.read_csv(fm_path,\n",
        "                     na_values=[0, -2.000000e-08],\n",
        "                     parse_dates=['date_recorded'],\n",
        "                     index_col='id')\n",
        "\n",
        "  # Drop constant columns\n",
        "  df.drop(columns=['recorded_by'], inplace=True)\n",
        "\n",
        "  # Create age feature\n",
        "  df['pump_age'] = df['date_recorded'].dt.year - df['construction_year']\n",
        "  df.drop(columns='date_recorded', inplace=True)\n",
        "\n",
        "  # Drop HCCCs\n",
        "  cutoff = 100\n",
        "  drop_cols = [col for col in df.select_dtypes('object').columns\n",
        "              if df[col].nunique() > cutoff]\n",
        "  df.drop(columns=drop_cols, inplace=True)\n",
        "\n",
        "  # Drop duplicate columns\n",
        "  dupe_cols = [col for col in df.head(100).T.duplicated().index # change 15 to 100!!!!\n",
        "               if df.head(100).T.duplicated()[col]]\n",
        "  df.drop(columns=dupe_cols, inplace=True)\n",
        "\n",
        "  return df\n",
        "\n",
        "# add the datapath if needed\n",
        "df = wrangle(fm_path='train_features.csv',\n",
        "             tv_path='train_labels.csv')\n",
        "\n",
        "X_test = wrangle(fm_path='test_features.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qArwLF4dRbTo"
      },
      "source": [
        "df.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jetWccxMqmzY"
      },
      "source": [
        "# II. Split Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-MPA0qlr-mK"
      },
      "source": [
        "## Split TV from FM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1tp2pnxqUvB"
      },
      "source": [
        "target = 'status_group'\n",
        "y = df[target]\n",
        "X = df.drop(columns=target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8jSWomGsLsw"
      },
      "source": [
        "# Training-Validation Split\n",
        "\n",
        "- Randomized split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPYl62lisKza"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y , test_size=0.2, random_state =42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WX9uvMMgs6J_"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "This is a **classification** problem, our baseline will be **accuracy**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXLLxnTDs328"
      },
      "source": [
        "print('baseline accuracy:', y_train.value_counts(normalize=True).max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA19NsrFtgTT"
      },
      "source": [
        "# IV. Build Model(s)\n",
        "\n",
        "- Missing values\n",
        "- Categorical values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBHAwvRZgEEv"
      },
      "source": [
        "**First Model:** Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m_3ManIjYCB"
      },
      "source": [
        "# Decision Tree\n",
        "model_dt = make_pipeline(\n",
        "    OrdinalEncoder(),\n",
        "    SimpleImputer(strategy='mean'),\n",
        "    DecisionTreeClassifier(random_state=42)\n",
        ")\n",
        "\n",
        "model_dt.fit(X_train, y_train);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2es5wzr8Omm"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfcNVGjxf3w5"
      },
      "source": [
        "plt.figure(figsize=(60,15));\n",
        "plot_tree(model_dt.named_steps['decisiontreeclassifier'],\n",
        "         max_depth=2,\n",
        "         feature_names=X_train.columns,\n",
        "         filled=True\n",
        "         );"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPDRWAjKgJkv"
      },
      "source": [
        "**Second Model:** Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhl3P5azgPUA"
      },
      "source": [
        "#Random Forest\n",
        "model_rf ="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7Cr2n7Vu9cb"
      },
      "source": [
        "# V. Check Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1bncI7svKf3"
      },
      "source": [
        "print('TREE: Training Accuracy:', model_dt.score(X_train, y_train))\n",
        "print('TREE: Validation Accuracy:', model_dt.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6BvApivgkLo"
      },
      "source": [
        "print('FOREST: Training Accuracy:',)\n",
        "print('FOREST: Validation Accuracy:',)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JoBVbzpQeQ0"
      },
      "source": [
        "# VI. Tune Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEmwKaz-oBc4"
      },
      "source": [
        "train_acc = []\n",
        "val_acc = []\n",
        "max_samples_list =\n",
        "for sample in max_samples_list:\n",
        "\n",
        "\n",
        "  model_rf_tune.fit(X_train, y_train)\n",
        "\n",
        "  train_acc.append(model_rf_tune.score(X_train, y_train))\n",
        "  val_acc.append(model_rf_tune.score(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgjQ_e9NhRqM"
      },
      "source": [
        "plt.plot(samples, train_acc, color='blue', label='training')\n",
        "plt.plot(samples, val_acc, color='orange', label='validation')\n",
        "plt.xlabel('max_samples')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw5mir81QglM"
      },
      "source": [
        "# VII. Communicate Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOGSy8PoGLok"
      },
      "source": [
        "# decision Tree\n",
        "features = model_dt.named_steps['ordinalencoder'].get_feature_names()\n",
        "gini = model_dt.named_steps['decisiontreeclassifier'].feature_importances_\n",
        "pd.Series(data=gini, index=features).sort_values(key=abs).tail(10).plot(kind='barh')\n",
        "plt.ylabel('features')\n",
        "plt.xlabel('gini importance');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_xZjkYOhge9"
      },
      "source": [
        "# random forest\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfSWuxScu8ll"
      },
      "source": [
        "#first tree in the Random Forest\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZjbCI9NBwG7y"
      },
      "source": [
        "#first tree in the Random Forest\n",
        "plt.figure(figsize=(60,15));\n",
        "plot_tree(\n",
        "         max_depth=2,\n",
        "         feature_names=X_train.columns,\n",
        "         filled=True\n",
        "         );"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}